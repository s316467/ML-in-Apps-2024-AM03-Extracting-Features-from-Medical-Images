{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","os.environ['KMP_DUPLICATE_LIB_OK'] = 'True '"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35842,"status":"ok","timestamp":1716457561970,"user":{"displayName":"Antonio Ferrigno","userId":"00461400557309860403"},"user_tz":-120},"id":"Ce1ibpotgbPe","outputId":"f5009cd0-bad7-4710-8f12-dc5044fac07a"},"outputs":[{"name":"stdout","output_type":"stream","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  2659  100  2659    0     0  10466      0 --:--:-- --:--:-- --:--:-- 10509\n","Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n","OK\n","57 packages can be upgraded. Run 'apt list --upgradable' to see them.\n","\u001b[1;33mW: \u001b[0mhttp://packages.cloud.google.com/apt/dists/gcsfuse-bionic/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\u001b[0m\n","The following NEW packages will be installed:\n","  gcsfuse\n","0 upgraded, 1 newly installed, 0 to remove and 57 not upgraded.\n","Need to get 10.4 MB of archives.\n","After this operation, 0 B of additional disk space will be used.\n","Selecting previously unselected package gcsfuse.\n","(Reading database ... 121920 files and directories currently installed.)\n","Preparing to unpack .../gcsfuse_2.0.1_amd64.deb ...\n","Unpacking gcsfuse (2.0.1) ...\n","Setting up gcsfuse (2.0.1) ...\n","{\"timestamp\":{\"seconds\":1716457560,\"nanos\":400204958},\"severity\":\"INFO\",\"message\":\"Start gcsfuse/2.0.1 (Go version go1.22.1) for app \\\"\\\" using mount point: /content/colab_directory\\n\"}\n","{\"timestamp\":{\"seconds\":1716457560,\"nanos\":400476392},\"severity\":\"INFO\",\"message\":\"GCSFuse mount command flags: {\\\"AppName\\\":\\\"\\\",\\\"Foreground\\\":false,\\\"ConfigFile\\\":\\\"\\\",\\\"MountOptions\\\":{},\\\"DirMode\\\":493,\\\"FileMode\\\":420,\\\"Uid\\\":-1,\\\"Gid\\\":-1,\\\"ImplicitDirs\\\":true,\\\"OnlyDir\\\":\\\"\\\",\\\"RenameDirLimit\\\":0,\\\"CustomEndpoint\\\":null,\\\"BillingProject\\\":\\\"\\\",\\\"KeyFile\\\":\\\"\\\",\\\"TokenUrl\\\":\\\"\\\",\\\"ReuseTokenFromUrl\\\":true,\\\"EgressBandwidthLimitBytesPerSecond\\\":-1,\\\"OpRateLimitHz\\\":-1,\\\"SequentialReadSizeMb\\\":200,\\\"MaxRetrySleep\\\":30000000000,\\\"StatCacheCapacity\\\":20460,\\\"StatCacheTTL\\\":60000000000,\\\"TypeCacheTTL\\\":60000000000,\\\"HttpClientTimeout\\\":0,\\\"MaxRetryDuration\\\":-1000000000,\\\"RetryMultiplier\\\":2,\\\"LocalFileCache\\\":false,\\\"TempDir\\\":\\\"\\\",\\\"ClientProtocol\\\":\\\"http1\\\",\\\"MaxConnsPerHost\\\":100,\\\"MaxIdleConnsPerHost\\\":100,\\\"EnableNonexistentTypeCache\\\":false,\\\"StackdriverExportInterval\\\":0,\\\"OtelCollectorAddress\\\":\\\"\\\",\\\"LogFile\\\":\\\"\\\",\\\"LogFormat\\\":\\\"json\\\",\\\"ExperimentalEnableJsonRead\\\":false,\\\"DebugFuseErrors\\\":true,\\\"DebugFuse\\\":false,\\\"DebugFS\\\":false,\\\"DebugGCS\\\":false,\\\"DebugHTTP\\\":false,\\\"DebugInvariants\\\":false,\\\"DebugMutex\\\":false}\"}\n","{\"timestamp\":{\"seconds\":1716457560,\"nanos\":400633496},\"severity\":\"INFO\",\"message\":\"GCSFuse mount config flags: {\\\"CreateEmptyFile\\\":false,\\\"Severity\\\":\\\"INFO\\\",\\\"Format\\\":\\\"json\\\",\\\"FilePath\\\":\\\"\\\",\\\"LogRotateConfig\\\":{\\\"MaxFileSizeMB\\\":512,\\\"BackupFileCount\\\":10,\\\"Compress\\\":true},\\\"MaxSizeMB\\\":-1,\\\"CacheFileForRangeRead\\\":false,\\\"CacheDir\\\":\\\"\\\",\\\"TtlInSeconds\\\":-9223372036854775808,\\\"TypeCacheMaxSizeMB\\\":4,\\\"StatCacheMaxSizeMB\\\":-9223372036854775808,\\\"EnableEmptyManagedFolders\\\":false,\\\"ConnPoolSize\\\":1}\"}\n","{\"timestamp\":{\"seconds\":1716457560,\"nanos\":701629541},\"severity\":\"INFO\",\"message\":\"File system has been successfully mounted.\"}\n","CRC_WSIs  CRC_WSIs_compressed_labels  CRC_WSIs_original  WIP\n"]}],"source":[" # \"excellent-shard-422915-n5\"\n","from google.colab import auth\n","\n","# PROJECT_ID = \"excellent-shard-422915-n5\"  # @param {type:\"string\"}\n","\n","auth.authenticate_user()\n","\n","!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n","\n","!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n","\n","!apt -qq update\n","\n","!apt -qq install gcsfuse\n","\n","!mkdir colab_directory\n","\n","!gcsfuse --implicit-dirs testopolito colab_directory\n","\n","!ls colab_directory"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":10435,"status":"ok","timestamp":1716457578571,"user":{"displayName":"Antonio Ferrigno","userId":"00461400557309860403"},"user_tz":-120},"id":"fJ9caGffklnI"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torchvision.utils import save_image\n","from PIL import Image\n","import numpy as np\n","import random\n","from sklearn import svm\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.svm import SVC\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":207,"status":"ok","timestamp":1716457580278,"user":{"displayName":"Antonio Ferrigno","userId":"00461400557309860403"},"user_tz":-120},"id":"Yfz3LtPHkpV_"},"outputs":[],"source":["# Definizione del generatore U-Net\n","class UNetGenerator(nn.Module):\n","    def __init__(self, input_channels=6, output_channels=3):\n","        super(UNetGenerator, self).__init__()\n","\n","        # Encoder\n","        self.enc1 = self.block(input_channels, 64, kernel_size=4, stride=2, padding=1, batch_norm=False)\n","        self.enc2 = self.block(64, 128, kernel_size=4, stride=2, padding=1)\n","        self.enc3 = self.block(128, 256, kernel_size=4, stride=2, padding=1)\n","        self.enc4 = self.block(256, 512, kernel_size=4, stride=2, padding=1)\n","        self.enc5 = self.block(512, 512, kernel_size=4, stride=2, padding=1)\n","        self.enc6 = self.block(512, 512, kernel_size=4, stride=2, padding=1)\n","        self.enc7 = self.block(512, 512, kernel_size=4, stride=2, padding=1)\n","        self.enc8 = self.block(512, 512, kernel_size=4, stride=2, padding=1, batch_norm=False)\n","\n","        # Decoder\n","        self.dec1 = self.block(512, 512, kernel_size=4, stride=2, padding=1, batch_norm=True, transpose=True)\n","        self.dec2 = self.block(1024, 512, kernel_size=4, stride=2, padding=1, batch_norm=True, transpose=True)\n","        self.dec3 = self.block(1024, 512, kernel_size=4, stride=2, padding=1, batch_norm=True, transpose=True)\n","        self.dec4 = self.block(1024, 512, kernel_size=4, stride=2, padding=1, batch_norm=True, transpose=True)\n","        self.dec5 = self.block(1024, 256, kernel_size=4, stride=2, padding=1, batch_norm=True, transpose=True)\n","        self.dec6 = self.block(512, 128, kernel_size=4, stride=2, padding=1, batch_norm=True, transpose=True)\n","        self.dec7 = self.block(256, 64, kernel_size=4, stride=2, padding=1, batch_norm=True, transpose=True)\n","        self.dec8 = self.block(128, output_channels, kernel_size=4, stride=2, padding=1, batch_norm=False, transpose=True)\n","\n","        self.tanh = nn.Tanh()\n","\n","    def block(self, in_channels, out_channels, kernel_size, stride, padding, batch_norm=True, transpose=False):\n","        layers = []\n","        if transpose:\n","            layers.append(nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False))\n","        else:\n","            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False))\n","        if batch_norm:\n","            layers.append(nn.BatchNorm2d(out_channels))\n","        layers.append(nn.ReLU(inplace=True))\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        # Encoder\n","        enc1 = self.enc1(x)\n","        enc2 = self.enc2(enc1)\n","        enc3 = self.enc3(enc2)\n","        enc4 = self.enc4(enc3)\n","        enc5 = self.enc5(enc4)\n","        enc6 = self.enc6(enc5)\n","        enc7 = self.enc7(enc6)\n","        enc8 = self.enc8(enc7)\n","\n","        # Decoder\n","        dec1 = self.dec1(enc8)\n","        dec1 = torch.cat([dec1, enc7], dim=1)\n","        dec2 = self.dec2(dec1)\n","        dec2 = torch.cat([dec2, enc6], dim=1)\n","        dec3 = self.dec3(dec2)\n","        dec3 = torch.cat([dec3, enc5], dim=1)\n","        dec4 = self.dec4(dec3)\n","        dec4 = torch.cat([dec4, enc4], dim=1)\n","        dec5 = self.dec5(dec4)\n","        dec5 = torch.cat([dec5, enc3], dim=1)\n","        dec6 = self.dec6(dec5)\n","        dec6 = torch.cat([dec6, enc2], dim=1)\n","        dec7 = self.dec7(dec6)\n","        dec7 = torch.cat([dec7, enc1], dim=1)\n","        dec8 = self.dec8(dec7)\n","\n","        return self.tanh(dec8), enc8"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Function to combine generated parts with the original image\n","def combine_images(original, generated, mask):\n","    return generated * mask + original * (1 - mask)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":222,"status":"ok","timestamp":1716457587054,"user":{"displayName":"Antonio Ferrigno","userId":"00461400557309860403"},"user_tz":-120},"id":"uWknS_wvkrqx"},"outputs":[],"source":["# Define the discriminator\n","class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","        self.main = nn.Sequential(\n","            nn.Conv2d(3, 64, 4, 2, 1),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(64, 128, 4, 2, 1),\n","            nn.BatchNorm2d(128),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(128, 256, 4, 2, 1),\n","            nn.BatchNorm2d(256),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(256, 512, 4, 2, 1),\n","            nn.BatchNorm2d(512),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(512, 1, 4, 1, 0),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        return self.main(x)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1716457588713,"user":{"displayName":"Antonio Ferrigno","userId":"00461400557309860403"},"user_tz":-120},"id":"Wt5OVgg5ktOL"},"outputs":[],"source":["# Utility function to create a masked image with random position and size\n","def create_random_masked_image(image):\n","    _, _, height, width = image.size()\n","    mask = torch.zeros_like(image)\n","\n","    # Define random position and size\n","    top = random.randint(0, height // 2)\n","    left = random.randint(0, width // 2)\n","    patch_height = random.randint(height // 4, height // 2)\n","    patch_width = random.randint(width // 4, width // 2)\n","\n","    # Apply mask\n","    mask[:, :, top:top + patch_height, left:left + patch_width] = 1\n","    masked_image = image.clone()\n","    masked_image[:, :, top:top + patch_height, left:left + patch_width] = 0\n","\n","    return masked_image, mask"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":199,"status":"ok","timestamp":1716457590189,"user":{"displayName":"Antonio Ferrigno","userId":"00461400557309860403"},"user_tz":-120},"id":"MMD1xGbnku3c"},"outputs":[],"source":["# Load and preprocess the image\n","def load_image(image_path):\n","    transform = transforms.Compose([\n","        transforms.Resize((64, 64)),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5,), (0.5,))\n","    ])\n","    image = Image.open(image_path).convert('RGB')\n","    return transform(image).unsqueeze(0)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1716457591490,"user":{"displayName":"Antonio Ferrigno","userId":"00461400557309860403"},"user_tz":-120},"id":"mc6Hztu4oMpA"},"outputs":[],"source":["# Function to convert a tensor to a PIL image and display it\n","def tensor_to_pil_image(tensor):\n","    tensor = tensor.clone().detach().cpu()\n","    tensor = tensor.squeeze(0)  # remove batch dimension\n","    tensor = transforms.Normalize((-1, -1, -1), (2, 2, 2))(tensor)  # unnormalize\n","    tensor = tensor.permute(1, 2, 0)  # convert to HWC format\n","    image = tensor.numpy()\n","    image = np.clip(image, 0, 1)\n","    return Image.fromarray((image * 255).astype(np.uint8))"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":301,"status":"ok","timestamp":1716457593488,"user":{"displayName":"Antonio Ferrigno","userId":"00461400557309860403"},"user_tz":-120},"id":"gJ1twlZrkvS_"},"outputs":[],"source":["# Initialize the generator and discriminator\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","generator = UNetGenerator().to(device)\n","discriminator = Discriminator().to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1716455161575,"user":{"displayName":"Antonio Ferrigno","userId":"00461400557309860403"},"user_tz":-120},"id":"RlFJToW8kwdt"},"outputs":[],"source":["# Load and mask the image\n","image_path = \"/content/colab_directory/CRC_WSIs_original/in_roi_patches/1.svs/10240_10240_mag1.png\"\n","image = load_image(image_path).to(device)\n","masked_image, mask = create_random_masked_image(image)\n","\n","# Concatenate masked image and mask along the channel dimension\n","z = torch.cat((masked_image, mask), dim=1)"]},{"cell_type":"code","execution_count":83,"metadata":{"executionInfo":{"elapsed":228,"status":"ok","timestamp":1716455024489,"user":{"displayName":"Antonio Ferrigno","userId":"00461400557309860403"},"user_tz":-120},"id":"v4lGDpbgoPyh"},"outputs":[],"source":["# Display masked image\n","masked_pil_image = tensor_to_pil_image(masked_image)\n","masked_pil_image.show()  # This will open the image in the default image viewer\n","masked_pil_image.save(\"masked_image.png\")  # Optionally save the image to disk"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1716457603105,"user":{"displayName":"Antonio Ferrigno","userId":"00461400557309860403"},"user_tz":-120},"id":"mpne9wMaky5D"},"outputs":[],"source":["# GAN training setup\n","criterion = nn.BCELoss()\n","optimizerG = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","optimizerD = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))"]},{"cell_type":"markdown","metadata":{"id":"0FDJAyOSvDdf"},"source":["# Temporary dataset with patient 1 only"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":228,"status":"ok","timestamp":1716457604760,"user":{"displayName":"Antonio Ferrigno","userId":"00461400557309860403"},"user_tz":-120},"id":"pT1jNkSBvC18"},"outputs":[],"source":["import os\n","from PIL import Image\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","import re\n","import numpy as np\n","\n","class patchesDataset(Dataset):\n","    def __init__(self, root_dir, patient_id, transform=None):\n","        self.root_dir = root_dir\n","        self.patient_id = patient_id\n","        self.transform = transform\n","        self.image_paths = []\n","        self.labels = []\n","        self.patients = []\n","        self.coordinates = []\n","\n","        # Process not_roi_patches (label 0)\n","        not_roi_dir = os.path.join(root_dir, 'not_roi_patches')\n","        patient_dir = os.path.join(not_roi_dir, f'{patient_id}.svs')\n","        for img_name in os.listdir(patient_dir):\n","            self.image_paths.append(os.path.join(patient_dir, img_name))\n","            self.labels.append(0)\n","            self.patients.append(patient_id)\n","            self.coordinates.append(self._extract_coordinates(img_name))\n","\n","        # Process in_roi_patches (label 1)\n","        in_roi_dir = os.path.join(root_dir, 'in_roi_patches')\n","        patient_dir = os.path.join(in_roi_dir, f'{patient_id}.svs')\n","        for img_name in os.listdir(patient_dir):\n","            self.image_paths.append(os.path.join(patient_dir, img_name))\n","            self.labels.append(1)\n","            self.patients.append(patient_id)\n","            self.coordinates.append(self._extract_coordinates(img_name))\n","\n","    def _extract_coordinates(self, img_name):\n","        # Extract x and y from the filename\n","        match = re.match(r'(\\d+)_(\\d+)_.*\\.png', img_name)\n","        if match:\n","            x, y = int(match.group(1)), int(match.group(2))\n","            return (x, y)\n","        else:\n","            raise ValueError(f\"Filename {img_name} does not match the expected pattern.\")\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.image_paths[idx]\n","        image = Image.open(img_path).convert(\"RGBA\")  # Ensure image is RGBA\n","        image = np.array(image)[:, :, :3]  # Drop the alpha channel\n","        image = Image.fromarray(image)  # Convert back to PIL image\n","        label = self.labels[idx]\n","        patient_id = self.patients[idx]\n","        coordinates = self.coordinates[idx]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, label, patient_id, coordinates"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2511,"status":"ok","timestamp":1716457637434,"user":{"displayName":"Antonio Ferrigno","userId":"00461400557309860403"},"user_tz":-120},"id":"rJ9-ciY5vHlC","outputId":"af3229ab-01a2-4f7a-e991-6cf1c685c044"},"outputs":[{"name":"stdout","output_type":"stream","text":["Batch of images shape: torch.Size([8, 3, 512, 512])\n","Batch of labels: tensor([1, 0, 1, 1, 1, 1, 1, 0])\n","Batch of patient IDs: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n","Batch of coordinates: [tensor([11776, 19456, 19968, 13824, 10240, 11264, 17920,  3584]), tensor([12800,  6656, 17408, 12800, 14336, 11776, 16384,  8704])]\n"]}],"source":["# Specify the patient ID you want to process\n","patient_id = 1\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor()\n","])\n","\n","dataset_temp = patchesDataset(root_dir=\"E:\\PoliTo\\Corsi PoliTo\\Semestre 4\\Machine learning in applications\\Progetto\\Dataset patches\\content\\colab_directory\\CRC_WSIs_original\\\\\", patient_id=patient_id, transform=transform)\n","dataloader_temp = DataLoader(dataset_temp, batch_size=8, shuffle=True)\n","\n","# Example of iterating through the dataloader\n","for images, labels, patient_ids, coords in dataloader_temp:\n","    print(f'Batch of images shape: {images.shape}')\n","    print(f'Batch of labels: {labels}')\n","    print(f'Batch of patient IDs: {patient_ids}')\n","    print(f'Batch of coordinates: {coords}')\n","    break  # Remove this break to iterate through all batches"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":194,"status":"ok","timestamp":1716457639712,"user":{"displayName":"Antonio Ferrigno","userId":"00461400557309860403"},"user_tz":-120},"id":"Mau92TDjwTPV"},"outputs":[],"source":["# Inizializza il dataloader per il paziente 1\n","patient_id = 1\n","dataset = patchesDataset(root_dir='E:\\PoliTo\\Corsi PoliTo\\Semestre 4\\Machine learning in applications\\Progetto\\Dataset patches\\content\\colab_directory\\CRC_WSIs_original\\\\', patient_id=patient_id, transform=transform)\n","dataloader = DataLoader(dataset, batch_size=8, shuffle=True)"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"NN6NQEgwk05v"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [0/10], d_loss: 1.3792, g_loss: 0.7160\n","Memory Allocated: 925.12 MB\n","Memory Cached: 3394.00 MB\n","Epoch [0/10], d_loss: 1.3802, g_loss: 0.7121\n","Memory Allocated: 925.12 MB\n","Memory Cached: 3434.00 MB\n","Epoch [0/10], d_loss: 1.3848, g_loss: 0.7143\n","Memory Allocated: 925.12 MB\n","Memory Cached: 3434.00 MB\n","Epoch [0/10], d_loss: 1.3826, g_loss: 0.7141\n","Memory Allocated: 925.12 MB\n","Memory Cached: 3434.00 MB\n","Epoch [0/10], d_loss: 1.3794, g_loss: 0.7110\n","Memory Allocated: 925.12 MB\n","Memory Cached: 3434.00 MB\n","Epoch [0/10], d_loss: 1.3853, g_loss: 0.7066\n","Memory Allocated: 925.12 MB\n","Memory Cached: 3434.00 MB\n","Epoch [0/10], d_loss: 1.3800, g_loss: 0.7126\n","Memory Allocated: 925.12 MB\n","Memory Cached: 3434.00 MB\n","Epoch [0/10], d_loss: 1.3797, g_loss: 0.7140\n","Memory Allocated: 925.12 MB\n","Memory Cached: 3434.00 MB\n","Epoch [0/10], d_loss: 1.3808, g_loss: 0.7104\n","Memory Allocated: 925.12 MB\n","Memory Cached: 3434.00 MB\n","Epoch [0/10], d_loss: 1.3829, g_loss: 0.7071\n","Memory Allocated: 925.12 MB\n","Memory Cached: 3434.00 MB\n","Epoch [0/10], d_loss: 1.3818, g_loss: 0.7133\n","Memory Allocated: 925.12 MB\n","Memory Cached: 3434.00 MB\n","Epoch [0/10], d_loss: 1.3839, g_loss: 0.7160\n","Memory Allocated: 925.12 MB\n","Memory Cached: 3434.00 MB\n","Epoch [0/10], d_loss: 1.3840, g_loss: 0.7092\n","Memory Allocated: 925.12 MB\n","Memory Cached: 3434.00 MB\n","Epoch [0/10], d_loss: 1.3799, g_loss: 0.7147\n","Memory Allocated: 925.12 MB\n","Memory Cached: 3434.00 MB\n","Epoch [0/10], d_loss: 1.3827, g_loss: 0.7157\n","Memory Allocated: 925.12 MB\n","Memory Cached: 3434.00 MB\n","Epoch [0/10], d_loss: 1.3805, g_loss: 0.7168\n","Memory Allocated: 925.12 MB\n","Memory Cached: 3434.00 MB\n","Epoch [0/10], d_loss: 1.3828, g_loss: 0.7148\n","Memory Allocated: 925.12 MB\n","Memory Cached: 3434.00 MB\n","Epoch [0/10], d_loss: 1.3822, g_loss: 0.7129\n","Memory Allocated: 925.12 MB\n","Memory Cached: 3434.00 MB\n","Epoch [0/10], d_loss: 1.3798, g_loss: 0.7143\n","Memory Allocated: 925.12 MB\n","Memory Cached: 3434.00 MB\n","Epoch [0/10], d_loss: 1.3794, g_loss: 0.7177\n","Memory Allocated: 925.12 MB\n","Memory Cached: 3434.00 MB\n","Epoch [0/10], d_loss: 1.3797, g_loss: 0.7184\n","Memory Allocated: 925.12 MB\n","Memory Cached: 3434.00 MB\n","Epoch [0/10], d_loss: 1.3799, g_loss: 0.7095\n","Memory Allocated: 925.12 MB\n","Memory Cached: 3434.00 MB\n","Epoch [0/10], d_loss: 1.3821, g_loss: 0.7097\n","Memory Allocated: 925.12 MB\n","Memory Cached: 3434.00 MB\n","Epoch [0/10], d_loss: 1.3847, g_loss: 0.7138\n","Memory Allocated: 925.12 MB\n","Memory Cached: 3434.00 MB\n","Epoch [0/10], d_loss: 1.3797, g_loss: 0.7132\n","Memory Allocated: 925.12 MB\n","Memory Cached: 3434.00 MB\n","Epoch [0/10], d_loss: 1.3793, g_loss: 0.7148\n","Memory Allocated: 925.12 MB\n","Memory Cached: 3434.00 MB\n","Epoch [0/10], d_loss: 1.3817, g_loss: 0.7109\n","Memory Allocated: 925.12 MB\n","Memory Cached: 3434.00 MB\n","Epoch [0/10], d_loss: 1.3820, g_loss: 0.7127\n","Memory Allocated: 925.12 MB\n","Memory Cached: 3434.00 MB\n","Epoch [0/10], d_loss: 1.3814, g_loss: 0.7168\n","Memory Allocated: 925.12 MB\n","Memory Cached: 3434.00 MB\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[32], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m labels_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# for epoch in range(num_epochs):\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels, patient_ids, coords \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m     12\u001b[0m     images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     13\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n","File \u001b[1;32mc:\\Users\\tony0\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[1;32mc:\\Users\\tony0\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[1;32mc:\\Users\\tony0\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[1;32mc:\\Users\\tony0\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","Cell \u001b[1;32mIn[11], line 52\u001b[0m, in \u001b[0;36mpatchesDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     50\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(img_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGBA\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Ensure image is RGBA\u001b[39;00m\n\u001b[0;32m     51\u001b[0m image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(image)[:, :, :\u001b[38;5;241m3\u001b[39m]  \u001b[38;5;66;03m# Drop the alpha channel\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(image)  \u001b[38;5;66;03m# Convert back to PIL image\u001b[39;00m\n\u001b[0;32m     53\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]\n\u001b[0;32m     54\u001b[0m patient_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatients[idx]\n","File \u001b[1;32mc:\\Users\\tony0\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3093\u001b[0m, in \u001b[0;36mfromarray\u001b[1;34m(obj, mode)\u001b[0m\n\u001b[0;32m   3090\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3091\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mtostring()\n\u001b[1;32m-> 3093\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frombuffer(mode, size, obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m, rawmode, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n","File \u001b[1;32mc:\\Users\\tony0\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3009\u001b[0m, in \u001b[0;36mfrombuffer\u001b[1;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[0;32m   3006\u001b[0m         im\u001b[38;5;241m.\u001b[39mreadonly \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   3007\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m im\n\u001b[1;32m-> 3009\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frombytes(mode, size, data, decoder_name, args)\n","File \u001b[1;32mc:\\Users\\tony0\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:2950\u001b[0m, in \u001b[0;36mfrombytes\u001b[1;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[0;32m   2947\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoder_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m args \u001b[38;5;241m==\u001b[39m ():\n\u001b[0;32m   2948\u001b[0m     args \u001b[38;5;241m=\u001b[39m mode\n\u001b[1;32m-> 2950\u001b[0m im \u001b[38;5;241m=\u001b[39m new(mode, size)\n\u001b[0;32m   2951\u001b[0m im\u001b[38;5;241m.\u001b[39mfrombytes(data, decoder_name, args)\n\u001b[0;32m   2952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m im\n","File \u001b[1;32mc:\\Users\\tony0\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:2914\u001b[0m, in \u001b[0;36mnew\u001b[1;34m(mode, size, color)\u001b[0m\n\u001b[0;32m   2912\u001b[0m     im\u001b[38;5;241m.\u001b[39mpalette \u001b[38;5;241m=\u001b[39m ImagePalette\u001b[38;5;241m.\u001b[39mImagePalette()\n\u001b[0;32m   2913\u001b[0m     color \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39mpalette\u001b[38;5;241m.\u001b[39mgetcolor(color)\n\u001b[1;32m-> 2914\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m im\u001b[38;5;241m.\u001b[39m_new(core\u001b[38;5;241m.\u001b[39mfill(mode, size, color))\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["def print_memory_usage():\n","    print(f'Memory Allocated: {torch.cuda.memory_allocated() / 1024**2:.2f} MB')\n","    print(f'Memory Cached: {torch.cuda.memory_reserved() / 1024**2:.2f} MB')\n","\n","num_epochs = 10\n","\n","embeddings_list = []\n","labels_list = []\n","\n","# for epoch in range(num_epochs):\n","for images, labels, patient_ids, coords in dataloader:\n","    images = images.to(device)\n","    labels = labels.to(device)\n","    \n","    # Create random masked image\n","    masked_images = []\n","    masks = []\n","    for image in images:\n","        masked_image, mask = create_random_masked_image(image.unsqueeze(0))\n","        masked_images.append(masked_image)\n","        masks.append(mask)\n","\n","    masked_images = torch.cat(masked_images).to(device)\n","    masks = torch.cat(masks).to(device)\n","\n","    # Train Discriminator\n","    optimizerD.zero_grad()\n","    real_labels = torch.ones(images.size(0), device=device)\n","    fake_labels = torch.zeros(images.size(0), device=device)\n","\n","    outputs = discriminator(images).view(images.size(0), -1).mean(1)\n","    d_loss_real = criterion(outputs, real_labels)\n","    d_loss_real.backward()\n","\n","    z = torch.cat((masked_images, masks), dim=1)\n","    generated_parts, embedding = generator(z)\n","    fake_images = combine_images(images, generated_parts, masks)\n","    outputs = discriminator(fake_images.detach()).view(images.size(0), -1).mean(1)\n","    d_loss_fake = criterion(outputs, fake_labels)\n","    d_loss_fake.backward()\n","\n","    optimizerD.step()\n","\n","    # Train Generator\n","    optimizerG.zero_grad()\n","    outputs = discriminator(fake_images).view(images.size(0), -1).mean(1)\n","    g_loss = criterion(outputs, real_labels)\n","    g_loss.backward()\n","\n","    optimizerG.step()\n","\n","    # Collect embeddings and labels for SVM training\n","    embeddings_list.append(embedding.view(embedding.size(0), -1).cpu().detach().numpy())\n","    labels_list.append(real_labels.cpu().detach().numpy())\n","\n","    embeddings_list.append(embedding.view(embedding.size(0), -1).cpu().detach().numpy())\n","    labels_list.append(fake_labels.cpu().detach().numpy())\n","    # if epoch % 2 == 0:\n","    print(f'Epoch [{epoch}/{num_epochs}], d_loss: {d_loss_real + d_loss_fake:.4f}, g_loss: {g_loss:.4f}')\n","    save_image(fake_images, f'output_{epoch}.png')\n","    # Debug: print memory usage\n","    print_memory_usage()\n","\n","    # Clear cache\n","    del masked_images, masks, outputs, fake_images, z, embedding, generated_parts\n","    torch.cuda.empty_cache()\n","\n","# Save embeddings and labels periodically\n","embeddings_list = np.concatenate(embeddings_list)\n","labels_list = np.concatenate(labels_list)\n","np.save('embeddings_list.npy', embeddings_list)\n","np.save('labels_list.npy', labels_list)\n"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"ZeM3aBT_u33U"},"outputs":[{"name":"stdout","output_type":"stream","text":["The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"]}],"source":["# Save the GAN models\n","torch.save({\n","    'generator_state_dict': generator.state_dict(),\n","    'discriminator_state_dict': discriminator.state_dict(),\n","    'optimizerG_state_dict': optimizerG.state_dict(),\n","    'optimizerD_state_dict': optimizerD.state_dict(),\n","}, 'gan_random_masks.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"aborted","timestamp":1716457692710,"user":{"displayName":"Antonio Ferrigno","userId":"00461400557309860403"},"user_tz":-120},"id":"gmxxWwFkk2tI"},"outputs":[],"source":["# Save the final generated image\n","save_image(fake_images, 'final_output.png')"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"o6QRv_Gpq9Z0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.3694581280788177\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","         0.0       0.38      0.45      0.41       198\n","         1.0       0.36      0.29      0.32       208\n","\n","    accuracy                           0.37       406\n","   macro avg       0.37      0.37      0.37       406\n","weighted avg       0.37      0.37      0.37       406\n","\n"]}],"source":["from sklearn.decomposition import PCA\n","\n","# Carica embeddings e labels\n","embeddings_list = np.load('embeddings_list.npy')\n","labels_list = np.load('labels_list.npy')\n","\n","# Riduci la dimensionalità con PCA\n","n_components = 100  # Puoi regolare questo numero in base alla tua esigenza\n","pca = PCA(n_components=n_components)\n","X_reduced = pca.fit_transform(embeddings_list)\n","\n","# Train/test split\n","X_train, X_test, y_train, y_test = train_test_split(X_reduced, labels_list, test_size=0.2, random_state=42)\n","\n","# Initialize and train the SVM classifier\n","svm_classifier = SVC(kernel='linear', C=1.0)\n","svm_classifier.fit(X_train, y_train)\n","\n","# Predict on the test set\n","y_pred = svm_classifier.predict(X_test)\n","\n","# Evaluate the classifier\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n","print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyODiHa7hn0jtR7QLjWKKmSt","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}

{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","os.environ['KMP_DUPLICATE_LIB_OK'] = 'True '\n","os.environ['TORCH_USE_CUDA_DSA'] = 'True '\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35842,"status":"ok","timestamp":1716457561970,"user":{"displayName":"Antonio Ferrigno","userId":"00461400557309860403"},"user_tz":-120},"id":"Ce1ibpotgbPe","outputId":"f5009cd0-bad7-4710-8f12-dc5044fac07a"},"outputs":[{"name":"stdout","output_type":"stream","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  2659  100  2659    0     0  10466      0 --:--:-- --:--:-- --:--:-- 10509\n","Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n","OK\n","57 packages can be upgraded. Run 'apt list --upgradable' to see them.\n","\u001b[1;33mW: \u001b[0mhttp://packages.cloud.google.com/apt/dists/gcsfuse-bionic/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\u001b[0m\n","The following NEW packages will be installed:\n","  gcsfuse\n","0 upgraded, 1 newly installed, 0 to remove and 57 not upgraded.\n","Need to get 10.4 MB of archives.\n","After this operation, 0 B of additional disk space will be used.\n","Selecting previously unselected package gcsfuse.\n","(Reading database ... 121920 files and directories currently installed.)\n","Preparing to unpack .../gcsfuse_2.0.1_amd64.deb ...\n","Unpacking gcsfuse (2.0.1) ...\n","Setting up gcsfuse (2.0.1) ...\n","{\"timestamp\":{\"seconds\":1716457560,\"nanos\":400204958},\"severity\":\"INFO\",\"message\":\"Start gcsfuse/2.0.1 (Go version go1.22.1) for app \\\"\\\" using mount point: /content/colab_directory\\n\"}\n","{\"timestamp\":{\"seconds\":1716457560,\"nanos\":400476392},\"severity\":\"INFO\",\"message\":\"GCSFuse mount command flags: {\\\"AppName\\\":\\\"\\\",\\\"Foreground\\\":false,\\\"ConfigFile\\\":\\\"\\\",\\\"MountOptions\\\":{},\\\"DirMode\\\":493,\\\"FileMode\\\":420,\\\"Uid\\\":-1,\\\"Gid\\\":-1,\\\"ImplicitDirs\\\":true,\\\"OnlyDir\\\":\\\"\\\",\\\"RenameDirLimit\\\":0,\\\"CustomEndpoint\\\":null,\\\"BillingProject\\\":\\\"\\\",\\\"KeyFile\\\":\\\"\\\",\\\"TokenUrl\\\":\\\"\\\",\\\"ReuseTokenFromUrl\\\":true,\\\"EgressBandwidthLimitBytesPerSecond\\\":-1,\\\"OpRateLimitHz\\\":-1,\\\"SequentialReadSizeMb\\\":200,\\\"MaxRetrySleep\\\":30000000000,\\\"StatCacheCapacity\\\":20460,\\\"StatCacheTTL\\\":60000000000,\\\"TypeCacheTTL\\\":60000000000,\\\"HttpClientTimeout\\\":0,\\\"MaxRetryDuration\\\":-1000000000,\\\"RetryMultiplier\\\":2,\\\"LocalFileCache\\\":false,\\\"TempDir\\\":\\\"\\\",\\\"ClientProtocol\\\":\\\"http1\\\",\\\"MaxConnsPerHost\\\":100,\\\"MaxIdleConnsPerHost\\\":100,\\\"EnableNonexistentTypeCache\\\":false,\\\"StackdriverExportInterval\\\":0,\\\"OtelCollectorAddress\\\":\\\"\\\",\\\"LogFile\\\":\\\"\\\",\\\"LogFormat\\\":\\\"json\\\",\\\"ExperimentalEnableJsonRead\\\":false,\\\"DebugFuseErrors\\\":true,\\\"DebugFuse\\\":false,\\\"DebugFS\\\":false,\\\"DebugGCS\\\":false,\\\"DebugHTTP\\\":false,\\\"DebugInvariants\\\":false,\\\"DebugMutex\\\":false}\"}\n","{\"timestamp\":{\"seconds\":1716457560,\"nanos\":400633496},\"severity\":\"INFO\",\"message\":\"GCSFuse mount config flags: {\\\"CreateEmptyFile\\\":false,\\\"Severity\\\":\\\"INFO\\\",\\\"Format\\\":\\\"json\\\",\\\"FilePath\\\":\\\"\\\",\\\"LogRotateConfig\\\":{\\\"MaxFileSizeMB\\\":512,\\\"BackupFileCount\\\":10,\\\"Compress\\\":true},\\\"MaxSizeMB\\\":-1,\\\"CacheFileForRangeRead\\\":false,\\\"CacheDir\\\":\\\"\\\",\\\"TtlInSeconds\\\":-9223372036854775808,\\\"TypeCacheMaxSizeMB\\\":4,\\\"StatCacheMaxSizeMB\\\":-9223372036854775808,\\\"EnableEmptyManagedFolders\\\":false,\\\"ConnPoolSize\\\":1}\"}\n","{\"timestamp\":{\"seconds\":1716457560,\"nanos\":701629541},\"severity\":\"INFO\",\"message\":\"File system has been successfully mounted.\"}\n","CRC_WSIs  CRC_WSIs_compressed_labels  CRC_WSIs_original  WIP\n"]}],"source":[" # \"excellent-shard-422915-n5\"\n","from google.colab import auth\n","\n","# PROJECT_ID = \"excellent-shard-422915-n5\"  # @param {type:\"string\"}\n","\n","auth.authenticate_user()\n","\n","!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n","\n","!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n","\n","!apt -qq update\n","\n","!apt -qq install gcsfuse\n","\n","!mkdir colab_directory\n","\n","!gcsfuse --implicit-dirs testopolito colab_directory\n","\n","!ls colab_directory"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":10435,"status":"ok","timestamp":1716457578571,"user":{"displayName":"Antonio Ferrigno","userId":"00461400557309860403"},"user_tz":-120},"id":"fJ9caGffklnI"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torchvision.utils import save_image\n","from PIL import Image\n","import numpy as np\n","import random\n","from sklearn import svm\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.svm import SVC\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":207,"status":"ok","timestamp":1716457580278,"user":{"displayName":"Antonio Ferrigno","userId":"00461400557309860403"},"user_tz":-120},"id":"Yfz3LtPHkpV_"},"outputs":[],"source":["# Definizione del generatore U-Net\n","class UNetGenerator(nn.Module):\n","    def __init__(self, input_channels=6, output_channels=3):\n","        super(UNetGenerator, self).__init__()\n","\n","        # Encoder\n","        self.enc1 = self.block(input_channels, 64, kernel_size=4, stride=2, padding=1, batch_norm=False)\n","        self.enc2 = self.block(64, 128, kernel_size=4, stride=2, padding=1)\n","        self.enc3 = self.block(128, 256, kernel_size=4, stride=2, padding=1)\n","        self.enc4 = self.block(256, 512, kernel_size=4, stride=2, padding=1)\n","        self.enc5 = self.block(512, 512, kernel_size=4, stride=2, padding=1)\n","        self.enc6 = self.block(512, 512, kernel_size=4, stride=2, padding=1)\n","        self.enc7 = self.block(512, 512, kernel_size=4, stride=2, padding=1)\n","        self.enc8 = self.block(512, 512, kernel_size=4, stride=2, padding=1, batch_norm=False)\n","\n","        # Decoder\n","        self.dec1 = self.block(512, 512, kernel_size=4, stride=2, padding=1, batch_norm=True, transpose=True)\n","        self.dec2 = self.block(1024, 512, kernel_size=4, stride=2, padding=1, batch_norm=True, transpose=True)\n","        self.dec3 = self.block(1024, 512, kernel_size=4, stride=2, padding=1, batch_norm=True, transpose=True)\n","        self.dec4 = self.block(1024, 512, kernel_size=4, stride=2, padding=1, batch_norm=True, transpose=True)\n","        self.dec5 = self.block(1024, 256, kernel_size=4, stride=2, padding=1, batch_norm=True, transpose=True)\n","        self.dec6 = self.block(512, 128, kernel_size=4, stride=2, padding=1, batch_norm=True, transpose=True)\n","        self.dec7 = self.block(256, 64, kernel_size=4, stride=2, padding=1, batch_norm=True, transpose=True)\n","        self.dec8 = self.block(128, output_channels, kernel_size=4, stride=2, padding=1, batch_norm=False, transpose=True)\n","\n","        self.tanh = nn.Tanh()\n","\n","    def block(self, in_channels, out_channels, kernel_size, stride, padding, batch_norm=True, transpose=False):\n","        layers = []\n","        if transpose:\n","            layers.append(nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False))\n","        else:\n","            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False))\n","        if batch_norm:\n","            layers.append(nn.BatchNorm2d(out_channels))\n","        layers.append(nn.ReLU(inplace=True))\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        # Encoder\n","        enc1 = self.enc1(x)\n","        enc2 = self.enc2(enc1)\n","        enc3 = self.enc3(enc2)\n","        enc4 = self.enc4(enc3)\n","        enc5 = self.enc5(enc4)\n","        enc6 = self.enc6(enc5)\n","        enc7 = self.enc7(enc6)\n","        enc8 = self.enc8(enc7)\n","\n","        # Decoder\n","        dec1 = self.dec1(enc8)\n","        dec1 = torch.cat([dec1, enc7], dim=1)\n","        dec2 = self.dec2(dec1)\n","        dec2 = torch.cat([dec2, enc6], dim=1)\n","        dec3 = self.dec3(dec2)\n","        dec3 = torch.cat([dec3, enc5], dim=1)\n","        dec4 = self.dec4(dec3)\n","        dec4 = torch.cat([dec4, enc4], dim=1)\n","        dec5 = self.dec5(dec4)\n","        dec5 = torch.cat([dec5, enc3], dim=1)\n","        dec6 = self.dec6(dec5)\n","        dec6 = torch.cat([dec6, enc2], dim=1)\n","        dec7 = self.dec7(dec6)\n","        dec7 = torch.cat([dec7, enc1], dim=1)\n","        dec8 = self.dec8(dec7)\n","\n","        return self.tanh(dec8), enc8"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Function to combine generated parts with the original image\n","def combine_images(original, generated, mask):\n","    return generated * mask + original * (1 - mask)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":222,"status":"ok","timestamp":1716457587054,"user":{"displayName":"Antonio Ferrigno","userId":"00461400557309860403"},"user_tz":-120},"id":"uWknS_wvkrqx"},"outputs":[],"source":["# Define the discriminator\n","class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","        self.main = nn.Sequential(\n","            nn.Conv2d(3, 64, 4, 2, 1),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(64, 128, 4, 2, 1),\n","            nn.BatchNorm2d(128),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(128, 256, 4, 2, 1),\n","            nn.BatchNorm2d(256),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(256, 512, 4, 2, 1),\n","            nn.BatchNorm2d(512),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(512, 1, 4, 1, 0),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        return self.main(x)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1716457588713,"user":{"displayName":"Antonio Ferrigno","userId":"00461400557309860403"},"user_tz":-120},"id":"Wt5OVgg5ktOL"},"outputs":[],"source":["# Utility function to create a masked image with random position and size\n","def create_random_masked_image(image):\n","    _, _, height, width = image.size()\n","    mask = torch.zeros_like(image)\n","\n","    # Define random position and size\n","    top = random.randint(0, height // 2)\n","    left = random.randint(0, width // 2)\n","    patch_height = random.randint(height // 4, height // 2)\n","    patch_width = random.randint(width // 4, width // 2)\n","\n","    # Apply mask\n","    mask[:, :, top:top + patch_height, left:left + patch_width] = 1\n","    masked_image = image.clone()\n","    masked_image[:, :, top:top + patch_height, left:left + patch_width] = 0\n","\n","    return masked_image, mask"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":199,"status":"ok","timestamp":1716457590189,"user":{"displayName":"Antonio Ferrigno","userId":"00461400557309860403"},"user_tz":-120},"id":"MMD1xGbnku3c"},"outputs":[],"source":["# Load and preprocess the image\n","def load_image(image_path):\n","    transform = transforms.Compose([\n","        transforms.Resize((64, 64)),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5,), (0.5,))\n","    ])\n","    image = Image.open(image_path).convert('RGB')\n","    return transform(image).unsqueeze(0)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1716457591490,"user":{"displayName":"Antonio Ferrigno","userId":"00461400557309860403"},"user_tz":-120},"id":"mc6Hztu4oMpA"},"outputs":[],"source":["# Function to convert a tensor to a PIL image and display it\n","def tensor_to_pil_image(tensor):\n","    tensor = tensor.clone().detach().cpu()\n","    tensor = tensor.squeeze(0)  # remove batch dimension\n","    tensor = transforms.Normalize((-1, -1, -1), (2, 2, 2))(tensor)  # unnormalize\n","    tensor = tensor.permute(1, 2, 0)  # convert to HWC format\n","    image = tensor.numpy()\n","    image = np.clip(image, 0, 1)\n","    return Image.fromarray((image * 255).astype(np.uint8))"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":301,"status":"ok","timestamp":1716457593488,"user":{"displayName":"Antonio Ferrigno","userId":"00461400557309860403"},"user_tz":-120},"id":"gJ1twlZrkvS_"},"outputs":[],"source":["# Initialize the generator and discriminator\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","generator = UNetGenerator().to(device)\n","discriminator = Discriminator().to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1716455161575,"user":{"displayName":"Antonio Ferrigno","userId":"00461400557309860403"},"user_tz":-120},"id":"RlFJToW8kwdt"},"outputs":[],"source":["# Load and mask the image\n","image_path = \"/content/colab_directory/CRC_WSIs_original/in_roi_patches/1.svs/10240_10240_mag1.png\"\n","image = load_image(image_path).to(device)\n","masked_image, mask = create_random_masked_image(image)\n","\n","# Concatenate masked image and mask along the channel dimension\n","z = torch.cat((masked_image, mask), dim=1)"]},{"cell_type":"code","execution_count":83,"metadata":{"executionInfo":{"elapsed":228,"status":"ok","timestamp":1716455024489,"user":{"displayName":"Antonio Ferrigno","userId":"00461400557309860403"},"user_tz":-120},"id":"v4lGDpbgoPyh"},"outputs":[],"source":["# Display masked image\n","masked_pil_image = tensor_to_pil_image(masked_image)\n","masked_pil_image.show()  # This will open the image in the default image viewer\n","masked_pil_image.save(\"masked_image.png\")  # Optionally save the image to disk"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1716457603105,"user":{"displayName":"Antonio Ferrigno","userId":"00461400557309860403"},"user_tz":-120},"id":"mpne9wMaky5D"},"outputs":[],"source":["# GAN training setup\n","criterion = nn.BCELoss()\n","optimizer_g = torch.optim.Adam(generator.parameters(), lr=0.00005, betas=(0.5, 0.999))\n","optimizer_d = torch.optim.Adam(discriminator.parameters(), lr=0.00005, betas=(0.5, 0.999))\n","\n","scheduler_g = torch.optim.lr_scheduler.StepLR(optimizer_g, step_size=30, gamma=0.1)\n","scheduler_d = torch.optim.lr_scheduler.StepLR(optimizer_d, step_size=30, gamma=0.1)"]},{"cell_type":"markdown","metadata":{"id":"0FDJAyOSvDdf"},"source":["# Temporary dataset with patient 1 only"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":228,"status":"ok","timestamp":1716457604760,"user":{"displayName":"Antonio Ferrigno","userId":"00461400557309860403"},"user_tz":-120},"id":"pT1jNkSBvC18"},"outputs":[],"source":["import os\n","from PIL import Image\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","import re\n","import numpy as np\n","\n","class patchesDataset(Dataset):\n","    def __init__(self, root_dir, patient_id, transform=None):\n","        self.root_dir = root_dir\n","        self.patient_id = patient_id\n","        self.transform = transform\n","        self.image_paths = []\n","        self.labels = []\n","        self.patients = []\n","        self.coordinates = []\n","\n","        # Process not_roi_patches (label 0)\n","        not_roi_dir = os.path.join(root_dir, 'not_roi_patches')\n","        patient_dir = os.path.join(not_roi_dir, f'{patient_id}.svs')\n","        for img_name in os.listdir(patient_dir):\n","            self.image_paths.append(os.path.join(patient_dir, img_name))\n","            self.labels.append(0)\n","            self.patients.append(patient_id)\n","            self.coordinates.append(self._extract_coordinates(img_name))\n","\n","        # Process in_roi_patches (label 1)\n","        in_roi_dir = os.path.join(root_dir, 'in_roi_patches')\n","        patient_dir = os.path.join(in_roi_dir, f'{patient_id}.svs')\n","        for img_name in os.listdir(patient_dir):\n","            self.image_paths.append(os.path.join(patient_dir, img_name))\n","            self.labels.append(1)\n","            self.patients.append(patient_id)\n","            self.coordinates.append(self._extract_coordinates(img_name))\n","\n","    def _extract_coordinates(self, img_name):\n","        # Extract x and y from the filename\n","        match = re.match(r'(\\d+)_(\\d+)_.*\\.png', img_name)\n","        if match:\n","            x, y = int(match.group(1)), int(match.group(2))\n","            return (x, y)\n","        else:\n","            raise ValueError(f\"Filename {img_name} does not match the expected pattern.\")\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.image_paths[idx]\n","        image = Image.open(img_path).convert(\"RGBA\")  # Ensure image is RGBA\n","        image = np.array(image)[:, :, :3]  # Drop the alpha channel\n","        image = Image.fromarray(image)  # Convert back to PIL image\n","        label = self.labels[idx]\n","        patient_id = self.patients[idx]\n","        coordinates = self.coordinates[idx]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, label, patient_id, coordinates"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2511,"status":"ok","timestamp":1716457637434,"user":{"displayName":"Antonio Ferrigno","userId":"00461400557309860403"},"user_tz":-120},"id":"rJ9-ciY5vHlC","outputId":"af3229ab-01a2-4f7a-e991-6cf1c685c044"},"outputs":[{"name":"stdout","output_type":"stream","text":["Batch of images shape: torch.Size([8, 3, 512, 512])\n","Batch of labels: tensor([1, 0, 1, 1, 1, 0, 0, 1])\n","Batch of patient IDs: tensor([1, 1, 1, 1, 1, 1, 1, 1])\n","Batch of coordinates: [tensor([14336, 17408,  8192, 16896,  5120,  6656, 21504, 20480]), tensor([13824,  5632, 16896, 16384, 16384, 11776,  3072, 12288])]\n"]}],"source":["# Specify the patient ID you want to process\n","patient_id = 1\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor()\n","])\n","\n","dataset_temp = patchesDataset(root_dir=\"E:\\PoliTo\\Corsi PoliTo\\Semestre 4\\Machine learning in applications\\Progetto\\Dataset patches\\content\\colab_directory\\CRC_WSIs_original\\\\\", patient_id=patient_id, transform=transform)\n","dataloader_temp = DataLoader(dataset_temp, batch_size=8, shuffle=True)\n","\n","# Example of iterating through the dataloader\n","for images, labels, patient_ids, coords in dataloader_temp:\n","    print(f'Batch of images shape: {images.shape}')\n","    print(f'Batch of labels: {labels}')\n","    print(f'Batch of patient IDs: {patient_ids}')\n","    print(f'Batch of coordinates: {coords}')\n","    break  # Remove this break to iterate through all batches"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":194,"status":"ok","timestamp":1716457639712,"user":{"displayName":"Antonio Ferrigno","userId":"00461400557309860403"},"user_tz":-120},"id":"Mau92TDjwTPV"},"outputs":[],"source":["# Inizializza il dataloader per il paziente 1\n","patient_id = 1\n","dataset = patchesDataset(root_dir='E:\\PoliTo\\Corsi PoliTo\\Semestre 4\\Machine learning in applications\\Progetto\\Dataset patches\\content\\colab_directory\\CRC_WSIs_original\\\\', patient_id=patient_id, transform=transform)\n","dataloader = DataLoader(dataset, batch_size=8, shuffle=True)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"NN6NQEgwk05v"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [0/5], d_loss: 1.4042, g_loss: 0.6999\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 2904.00 MB\n","Epoch [0/5], d_loss: 1.4655, g_loss: 0.6728\n","Memory Allocated: 1047.68 MB\n","Memory Cached: 3556.00 MB\n","Epoch [0/5], d_loss: 1.4108, g_loss: 0.6802\n","Memory Allocated: 1047.68 MB\n","Memory Cached: 3540.00 MB\n","Epoch [0/5], d_loss: 1.3967, g_loss: 0.6813\n","Memory Allocated: 1047.68 MB\n","Memory Cached: 3532.00 MB\n","Epoch [0/5], d_loss: 1.3913, g_loss: 0.6863\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3860, g_loss: 0.6903\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3849, g_loss: 0.6872\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3831, g_loss: 0.6966\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3870, g_loss: 0.6990\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3900, g_loss: 0.6873\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3756, g_loss: 0.6944\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3593, g_loss: 0.6979\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3666, g_loss: 0.7016\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3480, g_loss: 0.7408\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3722, g_loss: 0.7358\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3693, g_loss: 0.7220\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3704, g_loss: 0.6844\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3569, g_loss: 0.6880\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3517, g_loss: 0.7474\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3533, g_loss: 0.7348\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3464, g_loss: 0.7312\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3693, g_loss: 0.7303\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3555, g_loss: 0.7125\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3505, g_loss: 0.6948\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3382, g_loss: 0.6912\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3685, g_loss: 0.7302\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3385, g_loss: 0.7205\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3057, g_loss: 0.7243\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3078, g_loss: 0.7520\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3173, g_loss: 0.7578\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2933, g_loss: 0.6812\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3198, g_loss: 0.7595\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3409, g_loss: 0.7640\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3042, g_loss: 0.7063\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3029, g_loss: 0.7062\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2882, g_loss: 0.7301\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3039, g_loss: 0.7346\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3078, g_loss: 0.7264\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3446, g_loss: 0.7534\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2947, g_loss: 0.6742\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3516, g_loss: 0.7708\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3419, g_loss: 0.7417\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3070, g_loss: 0.7097\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3101, g_loss: 0.7352\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3029, g_loss: 0.6666\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3019, g_loss: 0.6638\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3158, g_loss: 0.7494\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3371, g_loss: 0.7517\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3434, g_loss: 0.7598\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3165, g_loss: 0.7325\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3091, g_loss: 0.7150\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3232, g_loss: 0.7369\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2932, g_loss: 0.7246\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3309, g_loss: 0.7471\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2871, g_loss: 0.6742\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2809, g_loss: 0.7233\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3228, g_loss: 0.7441\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3032, g_loss: 0.7046\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3129, g_loss: 0.7397\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2890, g_loss: 0.6879\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2617, g_loss: 0.6745\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2735, g_loss: 0.7135\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2880, g_loss: 0.6555\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2920, g_loss: 0.6941\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2828, g_loss: 0.6844\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2970, g_loss: 0.7289\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2816, g_loss: 0.6870\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2859, g_loss: 0.7198\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2790, g_loss: 0.7207\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2980, g_loss: 0.7140\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3453, g_loss: 0.7659\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2890, g_loss: 0.7248\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2777, g_loss: 0.7119\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2771, g_loss: 0.7091\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2741, g_loss: 0.7011\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2669, g_loss: 0.7061\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2953, g_loss: 0.6862\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2753, g_loss: 0.7285\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2986, g_loss: 0.7380\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2790, g_loss: 0.7131\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2824, g_loss: 0.7184\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3153, g_loss: 0.7594\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2916, g_loss: 0.7044\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2897, g_loss: 0.7251\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2668, g_loss: 0.7174\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2936, g_loss: 0.7053\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3059, g_loss: 0.7554\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2803, g_loss: 0.6624\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3165, g_loss: 0.7430\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3153, g_loss: 0.7525\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3176, g_loss: 0.7475\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2926, g_loss: 0.7323\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2874, g_loss: 0.7079\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2787, g_loss: 0.7211\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2752, g_loss: 0.7195\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3144, g_loss: 0.7275\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2897, g_loss: 0.6445\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2664, g_loss: 0.6837\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2852, g_loss: 0.7158\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3344, g_loss: 0.7573\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2929, g_loss: 0.7285\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2941, g_loss: 0.7261\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3185, g_loss: 0.7377\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3208, g_loss: 0.7539\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2936, g_loss: 0.7081\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3295, g_loss: 0.7496\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3199, g_loss: 0.7447\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2938, g_loss: 0.7316\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2993, g_loss: 0.7354\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2908, g_loss: 0.7275\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3180, g_loss: 0.7397\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2807, g_loss: 0.7154\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2816, g_loss: 0.7305\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2913, g_loss: 0.7339\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3070, g_loss: 0.7259\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3021, g_loss: 0.7459\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3133, g_loss: 0.7547\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2813, g_loss: 0.6870\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2810, g_loss: 0.7193\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3363, g_loss: 0.7611\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2587, g_loss: 0.7223\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2774, g_loss: 0.7034\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3116, g_loss: 0.7397\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.3414, g_loss: 0.7677\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2968, g_loss: 0.7273\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n","Epoch [0/5], d_loss: 1.2826, g_loss: 0.6603\n","Memory Allocated: 1048.68 MB\n","Memory Cached: 3552.00 MB\n"]},{"ename":"ValueError","evalue":"Using a target size (torch.Size([8])) that is different to the input size (torch.Size([5])) is deprecated. Please ensure they have the same size.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[14], line 35\u001b[0m\n\u001b[0;32m     31\u001b[0m fake_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((batch_size,), \u001b[38;5;241m0.1\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     34\u001b[0m outputs \u001b[38;5;241m=\u001b[39m discriminator(images)\u001b[38;5;241m.\u001b[39mview(images\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m d_loss_real \u001b[38;5;241m=\u001b[39m criterion(outputs, real_labels)\n\u001b[0;32m     36\u001b[0m d_loss_real\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     38\u001b[0m z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((images, masks), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Concatenate the whole image with the mask\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\tony0\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\tony0\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\tony0\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:618\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy(\u001b[38;5;28minput\u001b[39m, target, weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction)\n","File \u001b[1;32mc:\\Users\\tony0\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:3118\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3116\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[0;32m   3117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n\u001b[1;32m-> 3118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3120\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target\u001b[38;5;241m.\u001b[39msize(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m   3121\u001b[0m     )\n\u001b[0;32m   3123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3124\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n","\u001b[1;31mValueError\u001b[0m: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([5])) is deprecated. Please ensure they have the same size."]}],"source":["def print_memory_usage():\n","    print(f'Memory Allocated: {torch.cuda.memory_allocated() / 1024**2:.2f} MB')\n","    print(f'Memory Cached: {torch.cuda.memory_reserved() / 1024**2:.2f} MB')\n","\n","num_epochs = 5\n","\n","embeddings_list = []\n","labels_list = []\n","batch_size = 8\n","# epoch = 0\n","# Training loop\n","for epoch in range(num_epochs):\n","    for images, labels, patient_ids, coords in dataloader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        \n","        # Create random masked image\n","        masked_images = []\n","        masks = []\n","        for image in images:\n","            masked_image, mask = create_random_masked_image(image.unsqueeze(0))\n","            masked_images.append(masked_image)\n","            masks.append(mask)\n","\n","        masked_images = torch.cat(masked_images).to(device)\n","        masks = torch.cat(masks).to(device)\n","\n","        # Train Discriminator\n","        optimizer_d.zero_grad()\n","        real_labels = torch.full((batch_size,), 0.9, device=device)\n","        fake_labels = torch.full((batch_size,), 0.1, device=device)\n","\n","\n","        outputs = discriminator(images).view(images.size(0), -1).mean(1)\n","        d_loss_real = criterion(outputs, real_labels)\n","        d_loss_real.backward()\n","\n","        z = torch.cat((images, masks), dim=1)  # Concatenate the whole image with the mask\n","        generated_parts, embedding = generator(z)\n","        fake_images = combine_images(images, generated_parts, masks)\n","        outputs = discriminator(fake_images.detach()).view(images.size(0), -1).mean(1)\n","        d_loss_fake = criterion(outputs, fake_labels)\n","        d_loss_fake.backward()\n","\n","        optimizer_d.step()\n","\n","        # Train Generator\n","        optimizer_g.zero_grad()\n","        outputs = discriminator(fake_images).view(images.size(0), -1).mean(1)\n","        g_loss = criterion(outputs, real_labels)\n","        g_loss.backward()\n","\n","        optimizer_g.step()\n","\n","        # Collect embeddings and labels for SVM training\n","        embeddings_list.append(embedding.view(embedding.size(0), -1).cpu().detach().numpy())\n","        labels_list.append(real_labels.cpu().detach().numpy())\n","        embeddings_list.append(embedding.view(embedding.size(0), -1).cpu().detach().numpy())\n","        labels_list.append(fake_labels.cpu().detach().numpy())\n","\n","        print(f'Epoch [{epoch}/{num_epochs}], d_loss: {d_loss_real + d_loss_fake:.4f}, g_loss: {g_loss:.4f}')\n","        save_image(fake_images, f'output_{epoch}.png')\n","\n","        # Debug: print memory usage\n","        print_memory_usage()\n","\n","        # Clear cache\n","        del masked_images, masks, outputs, fake_images, z, embedding, generated_parts\n","        torch.cuda.empty_cache()\n","        scheduler_g.step()\n","        scheduler_d.step()\n","\n","# Save embeddings and labels periodically\n","embeddings_list = np.concatenate(embeddings_list)\n","labels_list = np.concatenate(labels_list)\n","np.save('embeddings_list.npy', embeddings_list)\n","np.save('labels_list.npy', labels_list)\n"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"ZeM3aBT_u33U"},"outputs":[{"name":"stdout","output_type":"stream","text":["The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"]}],"source":["# Save the GAN models\n","torch.save({\n","    'generator_state_dict': generator.state_dict(),\n","    'discriminator_state_dict': discriminator.state_dict(),\n","    'optimizerG_state_dict': optimizer_g.state_dict(),\n","    'optimizerD_state_dict': optimizer_d.state_dict(),\n","}, 'gan_random_masks.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(embeddings_list.shape)\n","print(labels_list.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"aborted","timestamp":1716457692710,"user":{"displayName":"Antonio Ferrigno","userId":"00461400557309860403"},"user_tz":-120},"id":"gmxxWwFkk2tI"},"outputs":[],"source":["# Save the final generated image\n","save_image(fake_images, 'final_output.png')"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"o6QRv_Gpq9Z0"},"outputs":[],"source":["from sklearn.decomposition import PCA\n","\n","# Carica embeddings e labels\n","embeddings_list = np.load('embeddings_list.npy')\n","labels_list = np.load('labels_list.npy')\n","\"\"\"\n","# Riduci la dimensionalità con PCA\n","n_components = 100  # Puoi regolare questo numero in base alla tua esigenza\n","pca = PCA(n_components=n_components)\n","X_reduced = pca.fit_transform(embeddings_list)\n","\"\"\"\n","# Train/test split\n","X_train, X_test, y_train, y_test = train_test_split(embeddings_list, labels_list, test_size=0.2, random_state=42)\n","\n","# Initialize and train the SVM classifier\n","svm_classifier = SVC(kernel='linear', C=1.0)\n","svm_classifier.fit(X_train, y_train)\n","\n","# Predict on the test set\n","y_pred = svm_classifier.predict(X_test)\n","\n","# Evaluate the classifier\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n","print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyODiHa7hn0jtR7QLjWKKmSt","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}

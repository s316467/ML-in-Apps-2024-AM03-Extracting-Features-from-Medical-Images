{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["kAhCrXP9ZtvJ","D78jv06QZ4bf","AxMGCWlEufMQ"],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ap5niYCzRTDw","executionInfo":{"status":"ok","timestamp":1716403409879,"user_tz":-120,"elapsed":4331,"user":{"displayName":"Mary","userId":"02296903614116367999"}},"outputId":"6d9e252c-112b-48fc-cd96-0e2ca70bc371"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["cd drive/MyDrive/MLinA_project/"],"metadata":{"id":"vxVmNEp-RdCM","executionInfo":{"status":"ok","timestamp":1716403417825,"user_tz":-120,"elapsed":306,"user":{"displayName":"Mary","userId":"02296903614116367999"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b1807f45-66a2-497e-cfd5-6f03f4f92124"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: 'drive/MyDrive/MLinA_project/'\n","/content/drive/MyDrive/MLinA_project\n"]}]},{"cell_type":"code","source":["import torch\n","import os\n","from PIL import Image\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","import re\n","import numpy as np"],"metadata":{"id":"n5JaDEBIO7zM","executionInfo":{"status":"ok","timestamp":1716403409880,"user_tz":-120,"elapsed":4,"user":{"displayName":"Mary","userId":"02296903614116367999"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["# Dataset creation"],"metadata":{"id":"lxagKvSaMxBh"}},{"cell_type":"code","source":["import dataset_patches\n","from dataset_patches import patchesDataset\n","\n","dataset = patchesDataset(root_dir='patches')\n","dataloader = DataLoader(dataset, batch_size=8, shuffle=True)"],"metadata":{"id":"zwtppedggiWD","executionInfo":{"status":"ok","timestamp":1716403423134,"user_tz":-120,"elapsed":1696,"user":{"displayName":"Mary","userId":"02296903614116367999"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["for images, labels, patient_ids, coordinates in dataloader:\n","    print(images[0].size())  # Tensor shape: (batch_size, channels, height, width)\n","    print(labels)  # Labels: 0 (no cancer) or 1 (cancer)\n","    print(patient_ids)  # Patient IDs: 1 to 24\n","    print(coordinates)  # Coordinates: (x, y) tuples\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5lTan-Z0RR_O","executionInfo":{"status":"ok","timestamp":1716403426512,"user_tz":-120,"elapsed":3380,"user":{"displayName":"Mary","userId":"02296903614116367999"}},"outputId":"10317aca-38a2-47fb-f232-03ce11d0a01d"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 512, 512])\n","tensor([0, 0, 0, 0, 1, 0, 1, 1])\n","tensor([14, 18, 21,  8,  2, 20, 20, 23])\n","[tensor([33792,  4608, 10752,  1536,  9216,  7168, 11776,  1536]), tensor([14848,  2048,  5120,  5120,  6144, 27648, 27136,  9216])]\n"]}]},{"cell_type":"markdown","source":["# Variational Autoencoder"],"metadata":{"id":"kAhCrXP9ZtvJ"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","from tqdm import tqdm\n","\n","# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Define the VAE model\n","class VAE(nn.Module):\n","    def __init__(self, latent_dim):\n","        super(VAE, self).__init__()\n","        self.latent_dim = latent_dim\n","\n","        # Encoder\n","        self.encoder = nn.Sequential(\n","            nn.Conv2d(3, 32, kernel_size=4, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.Flatten()\n","        )\n","\n","        self.fc_mu = nn.Linear(256*32*32, latent_dim)\n","        self.fc_logvar = nn.Linear(256*32*32, latent_dim)\n","\n","        # Decoder\n","        self.decoder = nn.Sequential(\n","            nn.Linear(latent_dim, 256*32*32),\n","            nn.ReLU(),\n","            nn.Unflatten(1, (256, 32, 32)),\n","            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(32, 3, kernel_size=4, stride=2, padding=1),\n","            nn.Sigmoid()\n","        )\n","\n","    def encode(self, x):\n","        x = self.encoder(x)\n","        mu = self.fc_mu(x)\n","        logvar = self.fc_logvar(x)\n","        return mu, logvar\n","\n","    def reparameterize(self, mu, logvar):\n","        std = torch.exp(0.5 * logvar)\n","        eps = torch.randn_like(std)\n","        return mu + eps * std\n","\n","    def decode(self, z):\n","        return self.decoder(z)\n","\n","    def forward(self, x):\n","        mu, logvar = self.encode(x)\n","        z = self.reparameterize(mu, logvar)\n","        return self.decode(z), mu, logvar\n","\n","# Reconstruction + KL divergence losses summed over all elements and batch\n","def loss_function(recon_x, x, mu, logvar):\n","    BCE = nn.functional.binary_cross_entropy(recon_x, x, reduction='sum')\n","    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n","    return BCE + KLD"],"metadata":{"id":"2kCpu20CZs_P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"D78jv06QZ4bf"}},{"cell_type":"code","source":["# Model, optimizer, and training parameters\n","\n","current_epochs = 0\n","\n","model = VAE(latent_dim=100).to(device)\n","try:\n","  model.load_state_dict(torch.load(f'vae_model_{current_epochs}.pth'))\n","  print('Model loaded correctly!')\n","except:\n","    ...\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","\n","# Training loop\n","num_epochs = 100\n","for epoch in range(num_epochs):\n","    model.train()\n","    total_loss = 0\n","    for batch_idx, (data, _, _, _) in enumerate(tqdm(dataloader, desc=f\"Epoch {epoch+current_epochs+1}/{num_epochs}\")):\n","        data = data.to(device)\n","        optimizer.zero_grad()\n","        recon_batch, mu, logvar = model(data)\n","        loss = loss_function(recon_batch, data, mu, logvar)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    print(f\"Epoch {epoch+current_epochs+1}/{num_epochs}, Loss: {total_loss / len(dataloader.dataset):.4f}\")\n","    if (epoch+1)%2==0 and epoch>0:\n","        torch.save(model.state_dict(), f'vae_{epoch+current_epochs+1}.pth')\n","\n","# Save the trained model\n","torch.save(model.state_dict(), f'vae_100.pth')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2h4YSWkUZ522","outputId":"cd195466-c9ea-4ed3-dc46-2f4a6085e205"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1/100: 100%|██████████| 510/510 [21:08<00:00,  2.49s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100, Loss: 472607.2335\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/100: 100%|██████████| 510/510 [02:42<00:00,  3.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/100, Loss: 460213.8909\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/100: 100%|██████████| 510/510 [02:41<00:00,  3.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/100, Loss: 456497.6767\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/100: 100%|██████████| 510/510 [02:41<00:00,  3.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/100, Loss: 455264.1543\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/100: 100%|██████████| 510/510 [02:45<00:00,  3.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5/100, Loss: 453340.5198\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6/100: 100%|██████████| 510/510 [02:40<00:00,  3.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6/100, Loss: 452499.7678\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7/100: 100%|██████████| 510/510 [02:44<00:00,  3.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7/100, Loss: 451029.2463\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8/100: 100%|██████████| 510/510 [02:45<00:00,  3.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8/100, Loss: 450278.6699\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9/100: 100%|██████████| 510/510 [02:43<00:00,  3.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9/100, Loss: 449788.7218\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10/100: 100%|██████████| 510/510 [02:40<00:00,  3.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/100, Loss: 448215.9512\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 11/100: 100%|██████████| 510/510 [02:40<00:00,  3.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 11/100, Loss: 448432.1664\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 12/100: 100%|██████████| 510/510 [02:39<00:00,  3.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 12/100, Loss: 446868.9502\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 13/100: 100%|██████████| 510/510 [02:39<00:00,  3.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 13/100, Loss: 446073.9155\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 14/100: 100%|██████████| 510/510 [02:39<00:00,  3.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 14/100, Loss: 443283.4474\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 15/100: 100%|██████████| 510/510 [02:40<00:00,  3.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 15/100, Loss: 441782.3061\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 16/100: 100%|██████████| 510/510 [02:40<00:00,  3.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 16/100, Loss: 441548.8330\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 17/100: 100%|██████████| 510/510 [02:40<00:00,  3.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 17/100, Loss: 440520.4613\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 18/100: 100%|██████████| 510/510 [02:40<00:00,  3.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 18/100, Loss: 439309.6442\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 19/100: 100%|██████████| 510/510 [02:40<00:00,  3.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 19/100, Loss: 439470.5268\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 20/100: 100%|██████████| 510/510 [02:40<00:00,  3.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 20/100, Loss: 438753.5188\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 21/100: 100%|██████████| 510/510 [02:40<00:00,  3.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 21/100, Loss: 437344.1273\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 22/100: 100%|██████████| 510/510 [02:40<00:00,  3.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 22/100, Loss: 436683.6216\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 23/100: 100%|██████████| 510/510 [02:43<00:00,  3.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 23/100, Loss: 436192.5903\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 24/100: 100%|██████████| 510/510 [02:42<00:00,  3.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 24/100, Loss: 436841.1710\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 25/100: 100%|██████████| 510/510 [02:43<00:00,  3.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 25/100, Loss: 436464.5814\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 26/100: 100%|██████████| 510/510 [02:40<00:00,  3.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 26/100, Loss: 435183.0895\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 27/100: 100%|██████████| 510/510 [02:41<00:00,  3.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 27/100, Loss: 434648.6175\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 28/100: 100%|██████████| 510/510 [02:40<00:00,  3.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 28/100, Loss: 434532.0893\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 29/100: 100%|██████████| 510/510 [02:40<00:00,  3.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 29/100, Loss: 434102.9588\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 30/100: 100%|██████████| 510/510 [02:41<00:00,  3.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 30/100, Loss: 434041.5383\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 31/100: 100%|██████████| 510/510 [02:40<00:00,  3.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 31/100, Loss: 433791.0779\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 32/100: 100%|██████████| 510/510 [02:40<00:00,  3.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 32/100, Loss: 433329.2456\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 33/100: 100%|██████████| 510/510 [02:41<00:00,  3.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 33/100, Loss: 432793.3968\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 34/100: 100%|██████████| 510/510 [02:41<00:00,  3.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 34/100, Loss: 432855.1450\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 35/100: 100%|██████████| 510/510 [02:39<00:00,  3.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 35/100, Loss: 432510.2789\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 36/100: 100%|██████████| 510/510 [02:39<00:00,  3.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 36/100, Loss: 432455.7602\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 37/100: 100%|██████████| 510/510 [02:40<00:00,  3.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 37/100, Loss: 432562.0608\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 38/100: 100%|██████████| 510/510 [02:40<00:00,  3.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 38/100, Loss: 432166.7637\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 39/100: 100%|██████████| 510/510 [02:39<00:00,  3.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 39/100, Loss: 431593.6047\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 40/100: 100%|██████████| 510/510 [02:41<00:00,  3.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 40/100, Loss: 431390.8113\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 41/100: 100%|██████████| 510/510 [02:41<00:00,  3.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 41/100, Loss: 431285.5754\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 42/100: 100%|██████████| 510/510 [02:44<00:00,  3.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 42/100, Loss: 431218.5502\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 43/100: 100%|██████████| 510/510 [02:45<00:00,  3.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 43/100, Loss: 431401.4483\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 44/100: 100%|██████████| 510/510 [02:44<00:00,  3.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 44/100, Loss: 431173.2488\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 45/100: 100%|██████████| 510/510 [02:46<00:00,  3.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 45/100, Loss: 430708.3409\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 46/100: 100%|██████████| 510/510 [02:44<00:00,  3.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 46/100, Loss: 430704.2701\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 47/100: 100%|██████████| 510/510 [02:43<00:00,  3.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 47/100, Loss: 430562.0105\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 48/100: 100%|██████████| 510/510 [02:41<00:00,  3.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 48/100, Loss: 430901.6449\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 49/100: 100%|██████████| 510/510 [02:40<00:00,  3.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 49/100, Loss: 431869.3346\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 50/100: 100%|██████████| 510/510 [02:41<00:00,  3.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 50/100, Loss: 430319.5532\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 51/100: 100%|██████████| 510/510 [02:40<00:00,  3.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 51/100, Loss: 429857.6732\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 52/100: 100%|██████████| 510/510 [02:41<00:00,  3.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 52/100, Loss: 429731.8997\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 53/100: 100%|██████████| 510/510 [02:40<00:00,  3.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 53/100, Loss: 429808.7932\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 54/100: 100%|██████████| 510/510 [02:43<00:00,  3.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 54/100, Loss: 429753.8902\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 55/100: 100%|██████████| 510/510 [02:41<00:00,  3.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 55/100, Loss: 429620.9039\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 56/100: 100%|██████████| 510/510 [02:40<00:00,  3.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 56/100, Loss: 429682.7313\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 57/100: 100%|██████████| 510/510 [02:42<00:00,  3.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 57/100, Loss: 430335.2606\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 58/100: 100%|██████████| 510/510 [02:41<00:00,  3.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 58/100, Loss: 429420.3647\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 59/100: 100%|██████████| 510/510 [02:43<00:00,  3.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 59/100, Loss: 429029.4118\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 60/100: 100%|██████████| 510/510 [02:45<00:00,  3.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 60/100, Loss: 429236.6064\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 61/100:  25%|██▌       | 128/510 [00:42<02:11,  2.90it/s]"]}]},{"cell_type":"markdown","source":["# Load the encoder and extract latent embeddings"],"metadata":{"id":"j153WQ983apZ"}},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = VAE(100).to(device)\n","model.load_state_dict(torch.load('vae_model_60.pth'))"],"metadata":{"id":"EzXaX_312Mgb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716389807740,"user_tz":-120,"elapsed":12991,"user":{"displayName":"Mary","userId":"02296903614116367999"}},"outputId":"7aba12c8-20dc-47ac-ba0c-df4102ac93ef"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# extract latent vectors for the entire dataset\n","def extract_latent_vectors(model, dataloader):\n","    latent_vectors = []\n","    labels = []\n","    model.eval()\n","    with torch.no_grad():\n","        for data,target,_,_ in dataloader:\n","            data = data.to(device)\n","            target = target.to(device)\n","            mu, logvar = model.encode(data)\n","            latent_vector = model.reparameterize(mu, logvar)\n","            latent_vectors.append(latent_vector.cpu().numpy())\n","            labels.append(target.cpu().numpy())\n","    return np.concatenate(latent_vectors), np.concatenate(labels)"],"metadata":{"id":"CpCTjX3AgW8Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["latent_vectors, labels = extract_latent_vectors(model, dataloader)"],"metadata":{"id":"lC_kmV6QPDbn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(latent_vectors.shape)\n","print(labels.shape)"],"metadata":{"id":"9Tpy1oNMhfUd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.save('latent_vectors_vae.npy', latent_vectors)\n","np.save('labels_vae.npy', labels)"],"metadata":{"id":"1_UNNsj_Thm-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Create SVM model\n"],"metadata":{"id":"_fqK8wST3d5e"}},{"cell_type":"code","source":["from sklearn.svm import SVC\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(latent_vectors, labels, test_size=0.2, random_state=42)\n","\n","# Initialize and train the SVM classifier\n","svm_classifier = SVC(kernel='linear', C=1.0)\n","svm_classifier.fit(X_train, y_train)\n","\n","# Predict on the test set\n","y_pred = svm_classifier.predict(X_test)\n","\n","# Evaluate the classifier\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n","print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"],"metadata":{"id":"SeliC-YTgv87"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Temporary dataset with patient 1 only"],"metadata":{"id":"AxMGCWlEufMQ"}},{"cell_type":"code","source":["import os\n","from PIL import Image\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","import re\n","import numpy as np\n","\n","class patchesDataset(Dataset):\n","    def __init__(self, root_dir, transform=None):\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.image_paths = []\n","        self.labels = []\n","        self.patients = []\n","        self.coordinates = []\n","\n","        # Process not_roi_patches (label 0)\n","        not_roi_dir = os.path.join(root_dir, 'not_roi_patches')\n","        for patient_id in range(1, 2):\n","            patient_dir = str(patient_id) + '.svs'\n","            patient_dir = os.path.join(not_roi_dir, str(patient_dir))\n","            for img_name in os.listdir(patient_dir):\n","                self.image_paths.append(os.path.join(patient_dir, img_name))\n","                self.labels.append(0)\n","                self.patients.append(patient_id)\n","                self.coordinates.append(self._extract_coordinates(img_name))\n","\n","        # Process in_roi_patches (label 1)\n","        in_roi_dir = os.path.join(root_dir, 'in_roi_patches')\n","        for patient_id in range(1, 2):\n","            if patient_id != 21:\n","                patient_dir = str(patient_id) + '.svs'\n","                patient_dir = os.path.join(in_roi_dir, str(patient_dir))\n","                for img_name in os.listdir(patient_dir):\n","                    self.image_paths.append(os.path.join(patient_dir, img_name))\n","                    self.labels.append(1)\n","                    self.patients.append(patient_id)\n","                    self.coordinates.append(self._extract_coordinates(img_name))\n","\n","    def _extract_coordinates(self, img_name):\n","        # Extract x and y from the filename\n","        match = re.match(r'(\\d+)_(\\d+)_.*\\.png', img_name)\n","        if match:\n","            x, y = int(match.group(1)), int(match.group(2))\n","            return (x, y)\n","        else:\n","            raise ValueError(f\"Filename {img_name} does not match the expected pattern.\")\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.image_paths[idx]\n","        image = Image.open(img_path).convert(\"RGBA\")  # Ensure image is RGBA\n","        image = np.array(image)[:, :, :3]  # Drop the alpha channel\n","        image = Image.fromarray(image)  # Convert back to PIL image\n","        label = self.labels[idx]\n","        patient_id = self.patients[idx]\n","        coordinates = self.coordinates[idx]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, label, patient_id, coordinates\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor()\n","])"],"metadata":{"id":"3tqBSTS_ujvp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_temp = patchesDataset(root_dir='patches', transform=transform)\n","dataloader_temp = DataLoader(dataset_temp, batch_size=8, shuffle=True)"],"metadata":{"id":"n_J9tDCyurXV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Results with only patient 1"],"metadata":{"id":"0QPdBg-vZQfh"}},{"cell_type":"code","source":["# RESULTS ONLY WITH PATIENT 1\n","\n","from sklearn.svm import SVC\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(latent_vectors, labels, test_size=0.2, random_state=42)\n","\n","# Initialize and train the SVM classifier\n","svm_classifier = SVC(kernel='linear', C=1.0)\n","svm_classifier.fit(X_train, y_train)\n","\n","# Predict on the test set\n","y_pred = svm_classifier.predict(X_test)\n","\n","# Evaluate the classifier\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n","print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716286559702,"user_tz":-120,"elapsed":1046,"user":{"displayName":"Mary","userId":"02296903614116367999"}},"outputId":"45e2b345-7adc-4717-aab8-f54cf79038a4","id":"uJPWVN43IPcG"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.8571428571428571\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.85      0.87      0.86       102\n","           1       0.87      0.84      0.85       101\n","\n","    accuracy                           0.86       203\n","   macro avg       0.86      0.86      0.86       203\n","weighted avg       0.86      0.86      0.86       203\n","\n"]}]}]}
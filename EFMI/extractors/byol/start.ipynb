{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1722258671190,"user":{"displayName":"Vitto The Wanderlust","userId":"00259578256183691585"},"user_tz":-120},"id":"jhjyEFKy4JBG","outputId":"43755361-8670-4644-ba2e-b23a21085a63"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"]}],"source":["ls\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17238,"status":"ok","timestamp":1724165224206,"user":{"displayName":"Vitto The Wanderlust","userId":"00259578256183691585"},"user_tz":-120},"id":"O9ukPrMOrY91"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","# Monta Google Drive\n","drive.mount('/content/drive')\n","\n","# Ora puoi usare i file in '/content/drive/My Drive/'\n","Data_Path = \"/content/drive/MyDrive/Colab_Notebooks/ML_INAPP_Proj/dataset/labeled_dataset\"\n"]},{"cell_type":"markdown","metadata":{"id":"LwMszoZj4a6q"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":289,"status":"ok","timestamp":1722258963639,"user":{"displayName":"Vitto The Wanderlust","userId":"00259578256183691585"},"user_tz":-120},"id":"jJnhdatroi63","outputId":"2b7f51b5-4923-46f5-9e1e-1ac262bba392"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[0m\u001b[01;34mEFMI\u001b[0m/  \u001b[01;34mold_notebooks\u001b[0m/  README.md  TODO.md  work_notebook.ipynb\n"]}],"source":["ls"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1233,"status":"ok","timestamp":1724165245988,"user":{"displayName":"Vitto The Wanderlust","userId":"00259578256183691585"},"user_tz":-120},"id":"dcmz2ndntHyA"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Colab_Notebooks/ML_INAPP_Proj/ML-in-Apps-2024-AM03-Extracting-Features-from-Medical-Images/EFMI/extractors/byol\n"]}],"source":["cd /content/drive/MyDrive/Colab_Notebooks/ML_INAPP_Proj/ML-in-Apps-2024-AM03-Extracting-Features-from-Medical-Images/EFMI/extractors/byol"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3343,"status":"ok","timestamp":1724165251499,"user":{"displayName":"Vitto The Wanderlust","userId":"00259578256183691585"},"user_tz":-120},"id":"HefDBB9yusEV","outputId":"d808fe7a-8f94-4099-81e8-fd3f9b6510f4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting byol-pytorch\n","  Downloading byol_pytorch-0.8.2-py3-none-any.whl.metadata (725 bytes)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from byol-pytorch) (0.32.1)\n","Collecting beartype (from byol-pytorch)\n","  Downloading beartype-0.18.5-py3-none-any.whl.metadata (30 kB)\n","Requirement already satisfied: torch\u003e=1.6 in /usr/local/lib/python3.10/dist-packages (from byol-pytorch) (2.3.0+cpu)\n","Requirement already satisfied: torchvision\u003e=0.8 in /usr/local/lib/python3.10/dist-packages (from byol-pytorch) (0.18.0+cpu)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.6-\u003ebyol-pytorch) (3.15.4)\n","Requirement already satisfied: typing-extensions\u003e=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.6-\u003ebyol-pytorch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.6-\u003ebyol-pytorch) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.6-\u003ebyol-pytorch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.6-\u003ebyol-pytorch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.6-\u003ebyol-pytorch) (2024.6.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision\u003e=0.8-\u003ebyol-pytorch) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,\u003e=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision\u003e=0.8-\u003ebyol-pytorch) (10.4.0)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate-\u003ebyol-pytorch) (24.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate-\u003ebyol-pytorch) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate-\u003ebyol-pytorch) (6.0.2)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate-\u003ebyol-pytorch) (0.23.5)\n","Requirement already satisfied: safetensors\u003e=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate-\u003ebyol-pytorch) (0.4.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub-\u003eaccelerate-\u003ebyol-pytorch) (2.32.3)\n","Requirement already satisfied: tqdm\u003e=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub-\u003eaccelerate-\u003ebyol-pytorch) (4.66.5)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch\u003e=1.6-\u003ebyol-pytorch) (2.1.5)\n","Requirement already satisfied: mpmath\u003c1.4,\u003e=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch\u003e=1.6-\u003ebyol-pytorch) (1.3.0)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub-\u003eaccelerate-\u003ebyol-pytorch) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub-\u003eaccelerate-\u003ebyol-pytorch) (3.7)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub-\u003eaccelerate-\u003ebyol-pytorch) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub-\u003eaccelerate-\u003ebyol-pytorch) (2024.7.4)\n","Downloading byol_pytorch-0.8.2-py3-none-any.whl (6.6 kB)\n","Downloading beartype-0.18.5-py3-none-any.whl (917 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m917.8/917.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: beartype, byol-pytorch\n","Successfully installed beartype-0.18.5 byol-pytorch-0.8.2\n"]}],"source":["!pip install byol-pytorch"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6305,"status":"ok","timestamp":1724165259682,"user":{"displayName":"Vitto The Wanderlust","userId":"00259578256183691585"},"user_tz":-120},"id":"HrlxzYtAewtP","outputId":"8289d122-efbe-4d48-8ccb-39665c9a94a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pytorch-lightning\n","  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: torch\u003e=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.3.0+cpu)\n","Requirement already satisfied: tqdm\u003e=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.5)\n","Requirement already satisfied: PyYAML\u003e=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.2)\n","Requirement already satisfied: fsspec\u003e=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]\u003e=2022.5.0-\u003epytorch-lightning) (2024.6.1)\n","Collecting torchmetrics\u003e=0.7.0 (from pytorch-lightning)\n","  Downloading torchmetrics-1.4.1-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (24.1)\n","Requirement already satisfied: typing-extensions\u003e=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.12.2)\n","Collecting lightning-utilities\u003e=0.10.0 (from pytorch-lightning)\n","  Downloading lightning_utilities-0.11.6-py3-none-any.whl.metadata (5.2 kB)\n","Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]\u003e=2022.5.0-\u003epytorch-lightning)\n","  Downloading aiohttp-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities\u003e=0.10.0-\u003epytorch-lightning) (71.0.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch\u003e=2.1.0-\u003epytorch-lightning) (3.15.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch\u003e=2.1.0-\u003epytorch-lightning) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch\u003e=2.1.0-\u003epytorch-lightning) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=2.1.0-\u003epytorch-lightning) (3.1.4)\n","Requirement already satisfied: numpy\u003e1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics\u003e=0.7.0-\u003epytorch-lightning) (1.26.4)\n","Collecting aiohappyeyeballs\u003e=2.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003e=2022.5.0-\u003epytorch-lightning)\n","  Downloading aiohappyeyeballs-2.4.0-py3-none-any.whl.metadata (5.9 kB)\n","Collecting aiosignal\u003e=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003e=2022.5.0-\u003epytorch-lightning)\n","  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n","Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003e=2022.5.0-\u003epytorch-lightning) (24.2.0)\n","Collecting frozenlist\u003e=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003e=2022.5.0-\u003epytorch-lightning)\n","  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multidict\u003c7.0,\u003e=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003e=2022.5.0-\u003epytorch-lightning)\n","  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n","Collecting yarl\u003c2.0,\u003e=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003e=2022.5.0-\u003epytorch-lightning)\n","  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n","Collecting async-timeout\u003c5.0,\u003e=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003e=2022.5.0-\u003epytorch-lightning)\n","  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch\u003e=2.1.0-\u003epytorch-lightning) (2.1.5)\n","Requirement already satisfied: mpmath\u003c1.4,\u003e=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch\u003e=2.1.0-\u003epytorch-lightning) (1.3.0)\n","Requirement already satisfied: idna\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl\u003c2.0,\u003e=1.0-\u003eaiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]\u003e=2022.5.0-\u003epytorch-lightning) (3.7)\n","Downloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.11.6-py3-none-any.whl (26 kB)\n","Downloading torchmetrics-1.4.1-py3-none-any.whl (866 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m866.2/866.2 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiohttp-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiohappyeyeballs-2.4.0-py3-none-any.whl (12 kB)\n","Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n","Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: multidict, lightning-utilities, frozenlist, async-timeout, aiohappyeyeballs, yarl, aiosignal, torchmetrics, aiohttp, pytorch-lightning\n","Successfully installed aiohappyeyeballs-2.4.0 aiohttp-3.10.5 aiosignal-1.3.1 async-timeout-4.0.3 frozenlist-1.4.1 lightning-utilities-0.11.6 multidict-6.0.5 pytorch-lightning-2.4.0 torchmetrics-1.4.1 yarl-1.9.4\n"]}],"source":["!pip install pytorch-lightning"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3072,"status":"ok","timestamp":1724165262751,"user":{"displayName":"Vitto The Wanderlust","userId":"00259578256183691585"},"user_tz":-120},"id":"YFtKlVb8mGDR","outputId":"0d47cf25-bc4f-47c6-cfae-dc1297e121da"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting kornia\n","  Downloading kornia-0.7.3-py2.py3-none-any.whl.metadata (7.7 kB)\n","Collecting kornia-rs\u003e=0.1.0 (from kornia)\n","  Downloading kornia_rs-0.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kornia) (24.1)\n","Requirement already satisfied: torch\u003e=1.9.1 in /usr/local/lib/python3.10/dist-packages (from kornia) (2.3.0+cpu)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.9.1-\u003ekornia) (3.15.4)\n","Requirement already satisfied: typing-extensions\u003e=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.9.1-\u003ekornia) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.9.1-\u003ekornia) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.9.1-\u003ekornia) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.9.1-\u003ekornia) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.9.1-\u003ekornia) (2024.6.1)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch\u003e=1.9.1-\u003ekornia) (2.1.5)\n","Requirement already satisfied: mpmath\u003c1.4,\u003e=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch\u003e=1.9.1-\u003ekornia) (1.3.0)\n","Downloading kornia-0.7.3-py2.py3-none-any.whl (833 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m833.3/833.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading kornia_rs-0.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: kornia-rs, kornia\n","Successfully installed kornia-0.7.3 kornia-rs-0.1.5\n"]}],"source":["!pip install kornia"]},{"cell_type":"markdown","metadata":{"id":"SyfiulBQ8GK7"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5581168,"status":"ok","timestamp":1718498566856,"user":{"displayName":"Vitto The Wanderlust","userId":"00259578256183691585"},"user_tz":-120},"id":"DbMpXwvv_5py","outputId":"80c184f0-6ef1-40dd-c1d4-07689762bdcb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n","100% 97.8M/97.8M [00:00\u003c00:00, 228MB/s]\n","Starting....\n","training\n","Loading checkpoint from checkpoints/checkpoint.66.pt\n","Training Progress:   0% 0/12 [00:00\u003c?, ?it/s]\n","Epoch 19:   0% 0/357 [00:00\u003c?, ?it/s]\u001b[A\n","Epoch 19 [Batch 0/357] Loss: 4.091:   0% 0/357 [00:20\u003c?, ?it/s]\u001b[AEpoch 19 Batch 0: Loss 4.091\n","\n","Epoch 19 [Batch 30/357] Loss: 4.092:   0% 0/357 [02:01\u003c?, ?it/s]\u001b[AEpoch 19 Batch 30: Loss 4.092\n","\n","Epoch 19 [Batch 60/357] Loss: 3.873:   0% 0/357 [03:45\u003c?, ?it/s]\u001b[AEpoch 19 Batch 60: Loss 3.873\n","\n","Epoch 19 [Batch 90/357] Loss: 3.955:   0% 0/357 [05:24\u003c?, ?it/s]\u001b[AEpoch 19 Batch 90: Loss 3.955\n","\n","Epoch 19 [Batch 120/357] Loss: 4.015:   0% 0/357 [07:08\u003c?, ?it/s]\u001b[AEpoch 19 Batch 120: Loss 4.015\n","\n","Epoch 19 [Batch 150/357] Loss: 4.003:   0% 0/357 [08:45\u003c?, ?it/s]\u001b[AEpoch 19 Batch 150: Loss 4.003\n","\n","Epoch 19 [Batch 180/357] Loss: 3.922:   0% 0/357 [10:30\u003c?, ?it/s]\u001b[AEpoch 19 Batch 180: Loss 3.922\n","\n","Epoch 19 [Batch 210/357] Loss: 3.769:   0% 0/357 [12:09\u003c?, ?it/s]\u001b[AEpoch 19 Batch 210: Loss 3.769\n","\n","Epoch 19 [Batch 240/357] Loss: 4.006:   0% 0/357 [13:52\u003c?, ?it/s]\u001b[AEpoch 19 Batch 240: Loss 4.006\n","\n","Epoch 19 [Batch 270/357] Loss: 4.019:   0% 0/357 [15:33\u003c?, ?it/s]\u001b[AEpoch 19 Batch 270: Loss 4.019\n","\n","Epoch 19 [Batch 300/357] Loss: 4.028:   0% 0/357 [17:16\u003c?, ?it/s]\u001b[AEpoch 19 Batch 300: Loss 4.028\n","\n","Epoch 19 [Batch 330/357] Loss: 4.102:   0% 0/357 [18:56\u003c?, ?it/s]\u001b[AEpoch 19 Batch 330: Loss 4.102\n","training complete\n","Training Progress:   8% 1/12 [20:23\u003c3:44:17, 1223.37s/it]\n","\n","Epoch 19 [Batch 330/357] Loss: 4.102:   0% 0/357 [20:23\u003c?, ?it/s]\n","\n","\n","Epoch 20 [Batch 0/357] Loss: 3.735:   0% 0/357 [00:03\u003c?, ?it/s]\u001b[A\u001b[AEpoch 20 Batch 0: Loss 3.735\n","\n","\n","Epoch 20 [Batch 30/357] Loss: 3.840:   0% 0/357 [01:10\u003c?, ?it/s]\u001b[A\u001b[AEpoch 20 Batch 30: Loss 3.840\n","\n","\n","Epoch 20 [Batch 60/357] Loss: 3.985:   0% 0/357 [02:18\u003c?, ?it/s]\u001b[A\u001b[AEpoch 20 Batch 60: Loss 3.985\n","\n","\n","Epoch 20 [Batch 90/357] Loss: 4.019:   0% 0/357 [03:26\u003c?, ?it/s]\u001b[A\u001b[AEpoch 20 Batch 90: Loss 4.019\n","\n","\n","Epoch 20 [Batch 120/357] Loss: 3.935:   0% 0/357 [04:32\u003c?, ?it/s]\u001b[A\u001b[AEpoch 20 Batch 120: Loss 3.935\n","\n","\n","Epoch 20 [Batch 150/357] Loss: 3.770:   0% 0/357 [05:39\u003c?, ?it/s]\u001b[A\u001b[AEpoch 20 Batch 150: Loss 3.770\n","\n","\n","Epoch 20 [Batch 180/357] Loss: 3.993:   0% 0/357 [06:46\u003c?, ?it/s]\u001b[A\u001b[AEpoch 20 Batch 180: Loss 3.993\n","\n","\n","Epoch 20 [Batch 210/357] Loss: 4.187:   0% 0/357 [07:53\u003c?, ?it/s]\u001b[A\u001b[AEpoch 20 Batch 210: Loss 4.187\n","\n","\n","Epoch 20 [Batch 240/357] Loss: 3.847:   0% 0/357 [09:01\u003c?, ?it/s]\u001b[A\u001b[AEpoch 20 Batch 240: Loss 3.847\n","\n","\n","Epoch 20 [Batch 270/357] Loss: 4.099:   0% 0/357 [10:08\u003c?, ?it/s]\u001b[A\u001b[AEpoch 20 Batch 270: Loss 4.099\n","\n","\n","Epoch 20 [Batch 300/357] Loss: 3.969:   0% 0/357 [11:15\u003c?, ?it/s]\u001b[A\u001b[AEpoch 20 Batch 300: Loss 3.969\n","\n","\n","Epoch 20 [Batch 330/357] Loss: 4.047:   0% 0/357 [12:22\u003c?, ?it/s]\u001b[A\u001b[AEpoch 20 Batch 330: Loss 4.047\n","training complete\n","Training Progress:  17% 2/12 [33:43\u003c2:42:21, 974.12s/it] \n","Epoch 20 [Batch 330/357] Loss: 4.047:   0% 0/357 [13:19\u003c?, ?it/s]\n","\n","Epoch 21 [Batch 0/357] Loss: 4.222:   0% 0/357 [00:03\u003c?, ?it/s]\u001b[AEpoch 21 Batch 0: Loss 4.222\n","\n","Epoch 21 [Batch 30/357] Loss: 3.992:   0% 0/357 [01:11\u003c?, ?it/s]\u001b[AEpoch 21 Batch 30: Loss 3.992\n","\n","Epoch 21 [Batch 60/357] Loss: 4.152:   0% 0/357 [02:18\u003c?, ?it/s]\u001b[AEpoch 21 Batch 60: Loss 4.152\n","\n","Epoch 21 [Batch 90/357] Loss: 3.910:   0% 0/357 [03:26\u003c?, ?it/s]\u001b[AEpoch 21 Batch 90: Loss 3.910\n","\n","Epoch 21 [Batch 120/357] Loss: 3.865:   0% 0/357 [04:35\u003c?, ?it/s]\u001b[AEpoch 21 Batch 120: Loss 3.865\n","\n","Epoch 21 [Batch 150/357] Loss: 4.209:   0% 0/357 [05:42\u003c?, ?it/s]\u001b[AEpoch 21 Batch 150: Loss 4.209\n","\n","Epoch 21 [Batch 180/357] Loss: 3.942:   0% 0/357 [06:50\u003c?, ?it/s]\u001b[AEpoch 21 Batch 180: Loss 3.942\n","\n","Epoch 21 [Batch 210/357] Loss: 3.789:   0% 0/357 [07:57\u003c?, ?it/s]\u001b[AEpoch 21 Batch 210: Loss 3.789\n","\n","Epoch 21 [Batch 240/357] Loss: 3.920:   0% 0/357 [09:04\u003c?, ?it/s]\u001b[AEpoch 21 Batch 240: Loss 3.920\n","\n","Epoch 21 [Batch 270/357] Loss: 4.179:   0% 0/357 [10:12\u003c?, ?it/s]\u001b[AEpoch 21 Batch 270: Loss 4.179\n","\n","Epoch 21 [Batch 300/357] Loss: 4.032:   0% 0/357 [11:20\u003c?, ?it/s]\u001b[AEpoch 21 Batch 300: Loss 4.032\n","\n","Epoch 21 [Batch 330/357] Loss: 3.982:   0% 0/357 [12:27\u003c?, ?it/s]\u001b[AEpoch 21 Batch 330: Loss 3.982\n","training complete\n","Training Progress:  25% 3/12 [47:06\u003c2:14:26, 896.28s/it]\n","\n","Epoch 21 [Batch 330/357] Loss: 3.982:   0% 0/357 [13:23\u003c?, ?it/s]\n","\n","\n","Epoch 22 [Batch 0/357] Loss: 3.745:   0% 0/357 [00:03\u003c?, ?it/s]\u001b[A\u001b[AEpoch 22 Batch 0: Loss 3.745\n","\n","\n","Epoch 22 [Batch 30/357] Loss: 3.992:   0% 0/357 [01:11\u003c?, ?it/s]\u001b[A\u001b[AEpoch 22 Batch 30: Loss 3.992\n","\n","\n","Epoch 22 [Batch 60/357] Loss: 3.854:   0% 0/357 [02:18\u003c?, ?it/s]\u001b[A\u001b[AEpoch 22 Batch 60: Loss 3.854\n","\n","\n","Epoch 22 [Batch 90/357] Loss: 3.923:   0% 0/357 [03:26\u003c?, ?it/s]\u001b[A\u001b[AEpoch 22 Batch 90: Loss 3.923\n","\n","\n","Epoch 22 [Batch 120/357] Loss: 4.189:   0% 0/357 [04:33\u003c?, ?it/s]\u001b[A\u001b[AEpoch 22 Batch 120: Loss 4.189\n","\n","\n","Epoch 22 [Batch 150/357] Loss: 3.764:   0% 0/357 [05:40\u003c?, ?it/s]\u001b[A\u001b[AEpoch 22 Batch 150: Loss 3.764\n","\n","\n","Epoch 22 [Batch 180/357] Loss: 3.798:   0% 0/357 [06:47\u003c?, ?it/s]\u001b[A\u001b[AEpoch 22 Batch 180: Loss 3.798\n","\n","\n","Epoch 22 [Batch 210/357] Loss: 4.084:   0% 0/357 [07:54\u003c?, ?it/s]\u001b[A\u001b[AEpoch 22 Batch 210: Loss 4.084\n","\n","\n","Epoch 22 [Batch 240/357] Loss: 3.947:   0% 0/357 [09:02\u003c?, ?it/s]\u001b[A\u001b[AEpoch 22 Batch 240: Loss 3.947\n","\n","\n","Epoch 22 [Batch 270/357] Loss: 3.964:   0% 0/357 [10:09\u003c?, ?it/s]\u001b[A\u001b[AEpoch 22 Batch 270: Loss 3.964\n","\n","\n","Epoch 22 [Batch 300/357] Loss: 4.005:   0% 0/357 [11:15\u003c?, ?it/s]\u001b[A\u001b[AEpoch 22 Batch 300: Loss 4.005\n","\n","\n","Epoch 22 [Batch 330/357] Loss: 3.909:   0% 0/357 [12:22\u003c?, ?it/s]\u001b[A\u001b[AEpoch 22 Batch 330: Loss 3.909\n","training complete\n","Training Progress:  33% 4/12 [1:00:26\u003c1:54:25, 858.14s/it]\n","Epoch 22 [Batch 330/357] Loss: 3.909:   0% 0/357 [13:19\u003c?, ?it/s]\n","\n","Epoch 23 [Batch 0/357] Loss: 3.943:   0% 0/357 [00:03\u003c?, ?it/s]\u001b[AEpoch 23 Batch 0: Loss 3.943\n","\n","Epoch 23 [Batch 30/357] Loss: 3.854:   0% 0/357 [01:11\u003c?, ?it/s]\u001b[AEpoch 23 Batch 30: Loss 3.854\n","\n","Epoch 23 [Batch 60/357] Loss: 4.181:   0% 0/357 [02:18\u003c?, ?it/s]\u001b[AEpoch 23 Batch 60: Loss 4.181\n","\n","Epoch 23 [Batch 90/357] Loss: 4.180:   0% 0/357 [03:26\u003c?, ?it/s]\u001b[AEpoch 23 Batch 90: Loss 4.180\n","\n","Epoch 23 [Batch 120/357] Loss: 3.942:   0% 0/357 [04:32\u003c?, ?it/s]\u001b[AEpoch 23 Batch 120: Loss 3.942\n","\n","Epoch 23 [Batch 150/357] Loss: 4.039:   0% 0/357 [05:39\u003c?, ?it/s]\u001b[AEpoch 23 Batch 150: Loss 4.039\n","\n","Epoch 23 [Batch 180/357] Loss: 3.932:   0% 0/357 [06:46\u003c?, ?it/s]\u001b[AEpoch 23 Batch 180: Loss 3.932\n","\n","Epoch 23 [Batch 210/357] Loss: 4.006:   0% 0/357 [07:52\u003c?, ?it/s]\u001b[AEpoch 23 Batch 210: Loss 4.006\n","\n","Epoch 23 [Batch 240/357] Loss: 3.879:   0% 0/357 [08:58\u003c?, ?it/s]\u001b[AEpoch 23 Batch 240: Loss 3.879\n","\n","Epoch 23 [Batch 270/357] Loss: 3.988:   0% 0/357 [10:04\u003c?, ?it/s]\u001b[AEpoch 23 Batch 270: Loss 3.988\n","\n","Epoch 23 [Batch 300/357] Loss: 3.858:   0% 0/357 [11:11\u003c?, ?it/s]\u001b[AEpoch 23 Batch 300: Loss 3.858\n","\n","Epoch 23 [Batch 330/357] Loss: 4.060:   0% 0/357 [12:18\u003c?, ?it/s]\u001b[AEpoch 23 Batch 330: Loss 4.060\n","training complete\n","Training Progress:  42% 5/12 [1:13:41\u003c1:37:28, 835.51s/it]\n","\n","Epoch 23 [Batch 330/357] Loss: 4.060:   0% 0/357 [13:15\u003c?, ?it/s]\n","\n","\n","Epoch 24 [Batch 0/357] Loss: 3.930:   0% 0/357 [00:03\u003c?, ?it/s]\u001b[A\u001b[AEpoch 24 Batch 0: Loss 3.930\n","\n","\n","Epoch 24 [Batch 30/357] Loss: 3.931:   0% 0/357 [01:10\u003c?, ?it/s]\u001b[A\u001b[AEpoch 24 Batch 30: Loss 3.931\n","\n","\n","Epoch 24 [Batch 60/357] Loss: 4.002:   0% 0/357 [02:16\u003c?, ?it/s]\u001b[A\u001b[AEpoch 24 Batch 60: Loss 4.002\n","\n","\n","Epoch 24 [Batch 90/357] Loss: 3.889:   0% 0/357 [03:22\u003c?, ?it/s]\u001b[A\u001b[AEpoch 24 Batch 90: Loss 3.889\n","\n","\n","Epoch 24 [Batch 120/357] Loss: 4.008:   0% 0/357 [04:28\u003c?, ?it/s]\u001b[A\u001b[AEpoch 24 Batch 120: Loss 4.008\n","\n","\n","Epoch 24 [Batch 150/357] Loss: 4.121:   0% 0/357 [05:33\u003c?, ?it/s]\u001b[A\u001b[AEpoch 24 Batch 150: Loss 4.121\n","\n","\n","Epoch 24 [Batch 180/357] Loss: 4.152:   0% 0/357 [06:36\u003c?, ?it/s]\u001b[A\u001b[AEpoch 24 Batch 180: Loss 4.152\n","\n","\n","Epoch 24 [Batch 210/357] Loss: 3.902:   0% 0/357 [07:37\u003c?, ?it/s]\u001b[A\u001b[AEpoch 24 Batch 210: Loss 3.902\n","\n","\n","Epoch 24 [Batch 240/357] Loss: 4.053:   0% 0/357 [08:39\u003c?, ?it/s]\u001b[A\u001b[AEpoch 24 Batch 240: Loss 4.053\n","\n","\n","Epoch 24 [Batch 270/357] Loss: 4.030:   0% 0/357 [09:41\u003c?, ?it/s]\u001b[A\u001b[AEpoch 24 Batch 270: Loss 4.030\n","\n","\n","Epoch 24 [Batch 300/357] Loss: 4.032:   0% 0/357 [10:43\u003c?, ?it/s]\u001b[A\u001b[AEpoch 24 Batch 300: Loss 4.032\n","\n","\n","Epoch 24 [Batch 330/357] Loss: 3.992:   0% 0/357 [11:45\u003c?, ?it/s]\u001b[A\u001b[AEpoch 24 Batch 330: Loss 3.992\n","training complete\n","Training Progress:  50% 6/12 [1:26:20\u003c1:20:55, 809.26s/it]\n","Epoch 24 [Batch 330/357] Loss: 3.992:   0% 0/357 [12:38\u003c?, ?it/s]\n","\n","Epoch 25 [Batch 0/357] Loss: 3.976:   0% 0/357 [00:03\u003c?, ?it/s]\u001b[AEpoch 25 Batch 0: Loss 3.976\n","\n","Epoch 25 [Batch 30/357] Loss: 4.159:   0% 0/357 [01:04\u003c?, ?it/s]\u001b[AEpoch 25 Batch 30: Loss 4.159\n","\n","Epoch 25 [Batch 60/357] Loss: 4.004:   0% 0/357 [02:06\u003c?, ?it/s]\u001b[AEpoch 25 Batch 60: Loss 4.004\n","\n","Epoch 25 [Batch 90/357] Loss: 4.063:   0% 0/357 [03:07\u003c?, ?it/s]\u001b[AEpoch 25 Batch 90: Loss 4.063\n","\n","Epoch 25 [Batch 120/357] Loss: 3.824:   0% 0/357 [04:08\u003c?, ?it/s]\u001b[AEpoch 25 Batch 120: Loss 3.824\n","\n","Epoch 25 [Batch 150/357] Loss: 3.954:   0% 0/357 [05:09\u003c?, ?it/s]\u001b[AEpoch 25 Batch 150: Loss 3.954\n","\n","Epoch 25 [Batch 180/357] Loss: 3.912:   0% 0/357 [06:11\u003c?, ?it/s]\u001b[AEpoch 25 Batch 180: Loss 3.912\n","\n","Epoch 25 [Batch 210/357] Loss: 3.943:   0% 0/357 [07:12\u003c?, ?it/s]\u001b[AEpoch 25 Batch 210: Loss 3.943\n","\n","Epoch 25 [Batch 240/357] Loss: 3.917:   0% 0/357 [08:13\u003c?, ?it/s]\u001b[AEpoch 25 Batch 240: Loss 3.917\n","\n","Epoch 25 [Batch 270/357] Loss: 4.063:   0% 0/357 [09:15\u003c?, ?it/s]\u001b[AEpoch 25 Batch 270: Loss 4.063\n","\n","Epoch 25 [Batch 300/357] Loss: 4.064:   0% 0/357 [10:16\u003c?, ?it/s]\u001b[AEpoch 25 Batch 300: Loss 4.064\n","\n","Epoch 25 [Batch 330/357] Loss: 4.094:   0% 0/357 [11:17\u003c?, ?it/s]\u001b[AEpoch 25 Batch 330: Loss 4.094\n","training complete\n","Training Progress:  58% 7/12 [1:38:29\u003c1:05:15, 783.18s/it]\n","\n","Epoch 25 [Batch 330/357] Loss: 4.094:   0% 0/357 [12:09\u003c?, ?it/s]\n","\n","\n","Epoch 26 [Batch 0/357] Loss: 4.179:   0% 0/357 [00:03\u003c?, ?it/s]\u001b[A\u001b[AEpoch 26 Batch 0: Loss 4.179\n","\n","\n","Epoch 26 [Batch 30/357] Loss: 3.933:   0% 0/357 [01:04\u003c?, ?it/s]\u001b[A\u001b[AEpoch 26 Batch 30: Loss 3.933\n","\n","\n","Epoch 26 [Batch 60/357] Loss: 4.058:   0% 0/357 [02:06\u003c?, ?it/s]\u001b[A\u001b[AEpoch 26 Batch 60: Loss 4.058\n","\n","\n","Epoch 26 [Batch 90/357] Loss: 4.030:   0% 0/357 [03:07\u003c?, ?it/s]\u001b[A\u001b[AEpoch 26 Batch 90: Loss 4.030\n","\n","\n","Epoch 26 [Batch 120/357] Loss: 4.028:   0% 0/357 [04:09\u003c?, ?it/s]\u001b[A\u001b[AEpoch 26 Batch 120: Loss 4.028\n","\n","\n","Epoch 26 [Batch 150/357] Loss: 3.969:   0% 0/357 [05:11\u003c?, ?it/s]\u001b[A\u001b[AEpoch 26 Batch 150: Loss 3.969\n","\n","\n","Epoch 26 [Batch 180/357] Loss: 4.001:   0% 0/357 [06:12\u003c?, ?it/s]\u001b[A\u001b[AEpoch 26 Batch 180: Loss 4.001\n","\n","\n","Epoch 26 [Batch 210/357] Loss: 3.999:   0% 0/357 [07:14\u003c?, ?it/s]\u001b[A\u001b[AEpoch 26 Batch 210: Loss 3.999\n","\n","\n","Epoch 26 [Batch 240/357] Loss: 3.929:   0% 0/357 [08:16\u003c?, ?it/s]\u001b[A\u001b[AEpoch 26 Batch 240: Loss 3.929\n","\n","\n","Epoch 26 [Batch 270/357] Loss: 3.996:   0% 0/357 [09:17\u003c?, ?it/s]\u001b[A\u001b[AEpoch 26 Batch 270: Loss 3.996\n","\n","\n","Epoch 26 [Batch 300/357] Loss: 3.977:   0% 0/357 [10:18\u003c?, ?it/s]\u001b[A\u001b[AEpoch 26 Batch 300: Loss 3.977\n","\n","\n","Epoch 26 [Batch 330/357] Loss: 4.220:   0% 0/357 [11:20\u003c?, ?it/s]\u001b[A\u001b[AEpoch 26 Batch 330: Loss 4.220\n","training complete\n","Training Progress:  67% 8/12 [1:50:42\u003c51:08, 767.24s/it]  \n","Epoch 26 [Batch 330/357] Loss: 4.220:   0% 0/357 [12:13\u003c?, ?it/s]\n","\n","Epoch 27 [Batch 0/357] Loss: 4.100:   0% 0/357 [00:03\u003c?, ?it/s]\u001b[AEpoch 27 Batch 0: Loss 4.100\n","\n","Epoch 27 [Batch 30/357] Loss: 3.860:   0% 0/357 [01:05\u003c?, ?it/s]\u001b[AEpoch 27 Batch 30: Loss 3.860\n","\n","Epoch 27 [Batch 60/357] Loss: 4.031:   0% 0/357 [02:07\u003c?, ?it/s]\u001b[AEpoch 27 Batch 60: Loss 4.031\n","\n","Epoch 27 [Batch 90/357] Loss: 3.878:   0% 0/357 [03:09\u003c?, ?it/s]\u001b[AEpoch 27 Batch 90: Loss 3.878\n","\n","Epoch 27 [Batch 120/357] Loss: 3.820:   0% 0/357 [04:11\u003c?, ?it/s]\u001b[AEpoch 27 Batch 120: Loss 3.820\n","\n","Epoch 27 [Batch 150/357] Loss: 3.932:   0% 0/357 [05:13\u003c?, ?it/s]\u001b[AEpoch 27 Batch 150: Loss 3.932\n","\n","Epoch 27 [Batch 180/357] Loss: 4.081:   0% 0/357 [06:15\u003c?, ?it/s]\u001b[AEpoch 27 Batch 180: Loss 4.081\n","\n","Epoch 27 [Batch 210/357] Loss: 3.999:   0% 0/357 [07:17\u003c?, ?it/s]\u001b[AEpoch 27 Batch 210: Loss 3.999\n","\n","Epoch 27 [Batch 240/357] Loss: 4.002:   0% 0/357 [08:19\u003c?, ?it/s]\u001b[AEpoch 27 Batch 240: Loss 4.002\n","\n","Epoch 27 [Batch 270/357] Loss: 3.948:   0% 0/357 [09:21\u003c?, ?it/s]\u001b[AEpoch 27 Batch 270: Loss 3.948\n","\n","Epoch 27 [Batch 300/357] Loss: 3.967:   0% 0/357 [10:23\u003c?, ?it/s]\u001b[AEpoch 27 Batch 300: Loss 3.967\n","\n","Epoch 27 [Batch 330/357] Loss: 4.034:   0% 0/357 [11:24\u003c?, ?it/s]\u001b[AEpoch 27 Batch 330: Loss 4.034\n","training complete\n","Training Progress:  75% 9/12 [2:03:00\u003c37:54, 758.12s/it]\n","\n","Epoch 27 [Batch 330/357] Loss: 4.034:   0% 0/357 [12:18\u003c?, ?it/s]\n","\n","\n","Epoch 28 [Batch 0/357] Loss: 4.140:   0% 0/357 [00:03\u003c?, ?it/s]\u001b[A\u001b[AEpoch 28 Batch 0: Loss 4.140\n","\n","\n","Epoch 28 [Batch 30/357] Loss: 3.759:   0% 0/357 [01:04\u003c?, ?it/s]\u001b[A\u001b[AEpoch 28 Batch 30: Loss 3.759\n","\n","\n","Epoch 28 [Batch 60/357] Loss: 3.957:   0% 0/357 [02:06\u003c?, ?it/s]\u001b[A\u001b[AEpoch 28 Batch 60: Loss 3.957\n","\n","\n","Epoch 28 [Batch 90/357] Loss: 4.004:   0% 0/357 [03:08\u003c?, ?it/s]\u001b[A\u001b[AEpoch 28 Batch 90: Loss 4.004\n","\n","\n","Epoch 28 [Batch 120/357] Loss: 3.882:   0% 0/357 [04:09\u003c?, ?it/s]\u001b[A\u001b[AEpoch 28 Batch 120: Loss 3.882\n","\n","\n","Epoch 28 [Batch 150/357] Loss: 4.191:   0% 0/357 [05:10\u003c?, ?it/s]\u001b[A\u001b[AEpoch 28 Batch 150: Loss 4.191\n","\n","\n","Epoch 28 [Batch 180/357] Loss: 4.022:   0% 0/357 [06:12\u003c?, ?it/s]\u001b[A\u001b[AEpoch 28 Batch 180: Loss 4.022\n","\n","\n","Epoch 28 [Batch 210/357] Loss: 4.008:   0% 0/357 [07:12\u003c?, ?it/s]\u001b[A\u001b[AEpoch 28 Batch 210: Loss 4.008\n","\n","\n","Epoch 28 [Batch 240/357] Loss: 4.145:   0% 0/357 [08:13\u003c?, ?it/s]\u001b[A\u001b[AEpoch 28 Batch 240: Loss 4.145\n","\n","\n","Epoch 28 [Batch 270/357] Loss: 4.044:   0% 0/357 [09:15\u003c?, ?it/s]\u001b[A\u001b[AEpoch 28 Batch 270: Loss 4.044\n","\n","\n","Epoch 28 [Batch 300/357] Loss: 4.110:   0% 0/357 [10:16\u003c?, ?it/s]\u001b[A\u001b[AEpoch 28 Batch 300: Loss 4.110\n","\n","\n","Epoch 28 [Batch 330/357] Loss: 3.860:   0% 0/357 [11:18\u003c?, ?it/s]\u001b[A\u001b[AEpoch 28 Batch 330: Loss 3.860\n","training complete\n","Training Progress:  83% 10/12 [2:15:10\u003c24:58, 749.45s/it]\n","Epoch 28 [Batch 330/357] Loss: 3.860:   0% 0/357 [12:10\u003c?, ?it/s]\n","\n","Epoch 29 [Batch 0/357] Loss: 4.048:   0% 0/357 [00:03\u003c?, ?it/s]\u001b[AEpoch 29 Batch 0: Loss 4.048\n","\n","Epoch 29 [Batch 30/357] Loss: 4.007:   0% 0/357 [01:04\u003c?, ?it/s]\u001b[AEpoch 29 Batch 30: Loss 4.007\n","\n","Epoch 29 [Batch 60/357] Loss: 4.214:   0% 0/357 [02:06\u003c?, ?it/s]\u001b[AEpoch 29 Batch 60: Loss 4.214\n","\n","Epoch 29 [Batch 90/357] Loss: 4.076:   0% 0/357 [03:07\u003c?, ?it/s]\u001b[AEpoch 29 Batch 90: Loss 4.076\n","\n","Epoch 29 [Batch 120/357] Loss: 4.007:   0% 0/357 [04:08\u003c?, ?it/s]\u001b[AEpoch 29 Batch 120: Loss 4.007\n","\n","Epoch 29 [Batch 150/357] Loss: 4.194:   0% 0/357 [05:10\u003c?, ?it/s]\u001b[AEpoch 29 Batch 150: Loss 4.194\n","\n","Epoch 29 [Batch 180/357] Loss: 3.897:   0% 0/357 [06:11\u003c?, ?it/s]\u001b[AEpoch 29 Batch 180: Loss 3.897\n","\n","Epoch 29 [Batch 210/357] Loss: 4.042:   0% 0/357 [07:12\u003c?, ?it/s]\u001b[AEpoch 29 Batch 210: Loss 4.042\n","\n","Epoch 29 [Batch 240/357] Loss: 4.112:   0% 0/357 [08:14\u003c?, ?it/s]\u001b[AEpoch 29 Batch 240: Loss 4.112\n","\n","Epoch 29 [Batch 270/357] Loss: 4.152:   0% 0/357 [09:15\u003c?, ?it/s]\u001b[AEpoch 29 Batch 270: Loss 4.152\n","\n","Epoch 29 [Batch 300/357] Loss: 3.928:   0% 0/357 [10:16\u003c?, ?it/s]\u001b[AEpoch 29 Batch 300: Loss 3.928\n","\n","Epoch 29 [Batch 330/357] Loss: 4.127:   0% 0/357 [11:17\u003c?, ?it/s]\u001b[AEpoch 29 Batch 330: Loss 4.127\n","training complete\n","Training Progress:  92% 11/12 [2:27:20\u003c12:23, 743.33s/it]\n","\n","Epoch 29 [Batch 330/357] Loss: 4.127:   0% 0/357 [12:09\u003c?, ?it/s]\n","\n","\n","Epoch 30 [Batch 0/357] Loss: 4.081:   0% 0/357 [00:03\u003c?, ?it/s]\u001b[A\u001b[AEpoch 30 Batch 0: Loss 4.081\n","\n","\n","Epoch 30 [Batch 30/357] Loss: 4.076:   0% 0/357 [01:05\u003c?, ?it/s]\u001b[A\u001b[AEpoch 30 Batch 30: Loss 4.076\n","\n","\n","Epoch 30 [Batch 60/357] Loss: 4.076:   0% 0/357 [02:06\u003c?, ?it/s]\u001b[A\u001b[AEpoch 30 Batch 60: Loss 4.076\n","\n","\n","Epoch 30 [Batch 90/357] Loss: 4.167:   0% 0/357 [03:07\u003c?, ?it/s]\u001b[A\u001b[AEpoch 30 Batch 90: Loss 4.167\n","\n","\n","Epoch 30 [Batch 120/357] Loss: 4.022:   0% 0/357 [04:09\u003c?, ?it/s]\u001b[A\u001b[AEpoch 30 Batch 120: Loss 4.022\n","\n","\n","Epoch 30 [Batch 150/357] Loss: 4.069:   0% 0/357 [05:10\u003c?, ?it/s]\u001b[A\u001b[AEpoch 30 Batch 150: Loss 4.069\n","\n","\n","Epoch 30 [Batch 180/357] Loss: 4.092:   0% 0/357 [06:12\u003c?, ?it/s]\u001b[A\u001b[AEpoch 30 Batch 180: Loss 4.092\n","\n","\n","Epoch 30 [Batch 210/357] Loss: 3.975:   0% 0/357 [07:13\u003c?, ?it/s]\u001b[A\u001b[AEpoch 30 Batch 210: Loss 3.975\n","\n","\n","Epoch 30 [Batch 240/357] Loss: 3.754:   0% 0/357 [08:15\u003c?, ?it/s]\u001b[A\u001b[AEpoch 30 Batch 240: Loss 3.754\n","\n","\n","Epoch 30 [Batch 270/357] Loss: 3.947:   0% 0/357 [09:16\u003c?, ?it/s]\u001b[A\u001b[AEpoch 30 Batch 270: Loss 3.947\n","\n","\n","Epoch 30 [Batch 300/357] Loss: 4.048:   0% 0/357 [10:17\u003c?, ?it/s]\u001b[A\u001b[AEpoch 30 Batch 300: Loss 4.048\n","\n","\n","Epoch 30 [Batch 330/357] Loss: 3.947:   0% 0/357 [11:18\u003c?, ?it/s]\u001b[A\u001b[AEpoch 30 Batch 330: Loss 3.947\n","training complete\n","Training Progress: 100% 12/12 [2:39:30\u003c00:00, 797.56s/it]\n","Epoch 30 [Batch 330/357] Loss: 3.947:   0% 0/357 [12:10\u003c?, ?it/s]\n"]}],"source":["!python main.py --image_folder \"/content/drive/MyDrive/Colab_Notebooks/ML_INAPP_Proj/dataset/labeled_dataset\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":945651,"status":"ok","timestamp":1722276415290,"user":{"displayName":"Vitto The Wanderlust","userId":"00259578256183691585"},"user_tz":-120},"id":"hFhUdvduroSM","outputId":"967f78a7-ae64-4398-b2c6-4ec9a2ded552"},"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Loading checkpoint from checkpoints/checkpoint.108.pt\n","odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.0.conv3.weight', 'layer1.0.bn3.weight', 'layer1.0.bn3.bias', 'layer1.0.bn3.running_mean', 'layer1.0.bn3.running_var', 'layer1.0.bn3.num_batches_tracked', 'layer1.0.downsample.0.weight', 'layer1.0.downsample.1.weight', 'layer1.0.downsample.1.bias', 'layer1.0.downsample.1.running_mean', 'layer1.0.downsample.1.running_var', 'layer1.0.downsample.1.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer1.1.conv3.weight', 'layer1.1.bn3.weight', 'layer1.1.bn3.bias', 'layer1.1.bn3.running_mean', 'layer1.1.bn3.running_var', 'layer1.1.bn3.num_batches_tracked', 'layer1.2.conv1.weight', 'layer1.2.bn1.weight', 'layer1.2.bn1.bias', 'layer1.2.bn1.running_mean', 'layer1.2.bn1.running_var', 'layer1.2.bn1.num_batches_tracked', 'layer1.2.conv2.weight', 'layer1.2.bn2.weight', 'layer1.2.bn2.bias', 'layer1.2.bn2.running_mean', 'layer1.2.bn2.running_var', 'layer1.2.bn2.num_batches_tracked', 'layer1.2.conv3.weight', 'layer1.2.bn3.weight', 'layer1.2.bn3.bias', 'layer1.2.bn3.running_mean', 'layer1.2.bn3.running_var', 'layer1.2.bn3.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.conv3.weight', 'layer2.0.bn3.weight', 'layer2.0.bn3.bias', 'layer2.0.bn3.running_mean', 'layer2.0.bn3.running_var', 'layer2.0.bn3.num_batches_tracked', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer2.1.conv3.weight', 'layer2.1.bn3.weight', 'layer2.1.bn3.bias', 'layer2.1.bn3.running_mean', 'layer2.1.bn3.running_var', 'layer2.1.bn3.num_batches_tracked', 'layer2.2.conv1.weight', 'layer2.2.bn1.weight', 'layer2.2.bn1.bias', 'layer2.2.bn1.running_mean', 'layer2.2.bn1.running_var', 'layer2.2.bn1.num_batches_tracked', 'layer2.2.conv2.weight', 'layer2.2.bn2.weight', 'layer2.2.bn2.bias', 'layer2.2.bn2.running_mean', 'layer2.2.bn2.running_var', 'layer2.2.bn2.num_batches_tracked', 'layer2.2.conv3.weight', 'layer2.2.bn3.weight', 'layer2.2.bn3.bias', 'layer2.2.bn3.running_mean', 'layer2.2.bn3.running_var', 'layer2.2.bn3.num_batches_tracked', 'layer2.3.conv1.weight', 'layer2.3.bn1.weight', 'layer2.3.bn1.bias', 'layer2.3.bn1.running_mean', 'layer2.3.bn1.running_var', 'layer2.3.bn1.num_batches_tracked', 'layer2.3.conv2.weight', 'layer2.3.bn2.weight', 'layer2.3.bn2.bias', 'layer2.3.bn2.running_mean', 'layer2.3.bn2.running_var', 'layer2.3.bn2.num_batches_tracked', 'layer2.3.conv3.weight', 'layer2.3.bn3.weight', 'layer2.3.bn3.bias', 'layer2.3.bn3.running_mean', 'layer2.3.bn3.running_var', 'layer2.3.bn3.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.conv3.weight', 'layer3.0.bn3.weight', 'layer3.0.bn3.bias', 'layer3.0.bn3.running_mean', 'layer3.0.bn3.running_var', 'layer3.0.bn3.num_batches_tracked', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer3.1.conv3.weight', 'layer3.1.bn3.weight', 'layer3.1.bn3.bias', 'layer3.1.bn3.running_mean', 'layer3.1.bn3.running_var', 'layer3.1.bn3.num_batches_tracked', 'layer3.2.conv1.weight', 'layer3.2.bn1.weight', 'layer3.2.bn1.bias', 'layer3.2.bn1.running_mean', 'layer3.2.bn1.running_var', 'layer3.2.bn1.num_batches_tracked', 'layer3.2.conv2.weight', 'layer3.2.bn2.weight', 'layer3.2.bn2.bias', 'layer3.2.bn2.running_mean', 'layer3.2.bn2.running_var', 'layer3.2.bn2.num_batches_tracked', 'layer3.2.conv3.weight', 'layer3.2.bn3.weight', 'layer3.2.bn3.bias', 'layer3.2.bn3.running_mean', 'layer3.2.bn3.running_var', 'layer3.2.bn3.num_batches_tracked', 'layer3.3.conv1.weight', 'layer3.3.bn1.weight', 'layer3.3.bn1.bias', 'layer3.3.bn1.running_mean', 'layer3.3.bn1.running_var', 'layer3.3.bn1.num_batches_tracked', 'layer3.3.conv2.weight', 'layer3.3.bn2.weight', 'layer3.3.bn2.bias', 'layer3.3.bn2.running_mean', 'layer3.3.bn2.running_var', 'layer3.3.bn2.num_batches_tracked', 'layer3.3.conv3.weight', 'layer3.3.bn3.weight', 'layer3.3.bn3.bias', 'layer3.3.bn3.running_mean', 'layer3.3.bn3.running_var', 'layer3.3.bn3.num_batches_tracked', 'layer3.4.conv1.weight', 'layer3.4.bn1.weight', 'layer3.4.bn1.bias', 'layer3.4.bn1.running_mean', 'layer3.4.bn1.running_var', 'layer3.4.bn1.num_batches_tracked', 'layer3.4.conv2.weight', 'layer3.4.bn2.weight', 'layer3.4.bn2.bias', 'layer3.4.bn2.running_mean', 'layer3.4.bn2.running_var', 'layer3.4.bn2.num_batches_tracked', 'layer3.4.conv3.weight', 'layer3.4.bn3.weight', 'layer3.4.bn3.bias', 'layer3.4.bn3.running_mean', 'layer3.4.bn3.running_var', 'layer3.4.bn3.num_batches_tracked', 'layer3.5.conv1.weight', 'layer3.5.bn1.weight', 'layer3.5.bn1.bias', 'layer3.5.bn1.running_mean', 'layer3.5.bn1.running_var', 'layer3.5.bn1.num_batches_tracked', 'layer3.5.conv2.weight', 'layer3.5.bn2.weight', 'layer3.5.bn2.bias', 'layer3.5.bn2.running_mean', 'layer3.5.bn2.running_var', 'layer3.5.bn2.num_batches_tracked', 'layer3.5.conv3.weight', 'layer3.5.bn3.weight', 'layer3.5.bn3.bias', 'layer3.5.bn3.running_mean', 'layer3.5.bn3.running_var', 'layer3.5.bn3.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.conv3.weight', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.bn3.running_mean', 'layer4.0.bn3.running_var', 'layer4.0.bn3.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'layer4.1.conv3.weight', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.1.bn3.running_mean', 'layer4.1.bn3.running_var', 'layer4.1.bn3.num_batches_tracked', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.bn1.num_batches_tracked', 'layer4.2.conv2.weight', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.bn2.num_batches_tracked', 'layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'layer4.2.bn3.running_mean', 'layer4.2.bn3.running_var', 'layer4.2.bn3.num_batches_tracked', 'fc.weight', 'fc.bias'])\n","  0% 0/446 [00:00\u003c?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","100% 446/446 [1:09:00\u003c00:00,  9.28s/it]\n","Embeddings saved\n"]}],"source":["!python get_features.py --image_folder \"/content/drive/MyDrive/Colab_Notebooks/ML_INAPP_Proj/dataset/labeled_dataset\""]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":357282,"status":"ok","timestamp":1724165691320,"user":{"displayName":"Vitto The Wanderlust","userId":"00259578256183691585"},"user_tz":-120},"id":"5Ga5tnf-EH62","outputId":"6c42a345-08d8-4ba9-b027-fa7c4b6c0705"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading embeddings...\n","Embeddings loaded\n","Accuracy on training set: 0.9203679369250986\n","Classification Report on training set:\n","              precision    recall  f1-score   support\n","\n","           0       0.93      0.92      0.92      5914\n","           1       0.91      0.92      0.92      5501\n","\n","    accuracy                           0.92     11415\n","   macro avg       0.92      0.92      0.92     11415\n","weighted avg       0.92      0.92      0.92     11415\n","\n","Confusion Matrix on training set:\n","[[5424  490]\n"," [ 419 5082]]\n","\n","Accuracy on test set: 0.834968465311843\n","Classification Report on test set:\n","              precision    recall  f1-score   support\n","\n","           0       0.84      0.84      0.84      1475\n","           1       0.83      0.83      0.83      1379\n","\n","    accuracy                           0.83      2854\n","   macro avg       0.83      0.83      0.83      2854\n","weighted avg       0.83      0.83      0.83      2854\n","\n","Confusion Matrix on test set:\n","[[1240  235]\n"," [ 236 1143]]\n"]}],"source":["!python downstream.py"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}